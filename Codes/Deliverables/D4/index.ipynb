{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a723d825",
   "metadata": {},
   "source": [
    "# Deliverable #4\n",
    "\n",
    "The fourth deliverable (skips three as it isn't a coding deliverable). This deliverable is more like a supplementary to the [Deliverable #2](../D2/README.md); implementing three new neural network architectures.\n",
    "\n",
    "This `index` file serves as the testing ground for the flow that will later be used by the separate notebooks when fine tuning them.\n",
    "\n",
    "All other notebooks are:\n",
    "- [VGG16](vgg16.ipynb) - VGG16\n",
    "- [IV3](iv3.ipynb) - InceptionV3\n",
    "- [RN50](rn50.ipynb) - Resnet50\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "Download the CIFAR-10 dataset from a reliable dataset repository such as TensorFlow Datasets or directly from the official source. The CIFAR-10 dataset contains 60,000 color images sized at 32x32 pixels, categorized into 10 classes with 6,000 images per class. It is divided into 50,000 training images and 10,000 test images. The training set is further split into five batches, each containing 10,000 images, while the test batch contains 1,000 randomly selected images from each class. The training batches include the remaining images in random order, and although each class has 5,000 training samples in total, individual batches may have varying distributions.\n",
    "\n",
    "For this task, you are required to implement and fine-tune three well-known deep convolutional neural network architectures: **VGG16**, **InceptionV3**, and **ResNet50**. Use transfer learning techniques by loading pretrained weights (e.g., from ImageNet), adjusting the input size if necessary, and appending appropriate classification layers for the 10-class output of CIFAR-10. Train each model on the CIFAR-10 training set and evaluate on the test set. You should also explore and apply regularization techniques such as dropout, batch normalization, and weight decay to improve performance and avoid overfitting.\n",
    "\n",
    "Present the performance of each model using both visual and quantitative methods. This includes plotting the training and validation accuracy and loss across epochs using the model history, and evaluating classification performance with a confusion matrix. Your analysis should compare how the three models performed, highlighting differences in accuracy, generalization, and training time.\n",
    "\n",
    "Finally, write a report summarizing your findings and classification results. The report should include an overview of each architecture, your implementation approach, the regularization techniques applied, and the evaluation results. Save the report as a PDF file named D4_LastName.pdf. Additionally, submit a ZIP file named D4_LastName.zip containing your complete code (notebooks or scripts), model files if any, and any helper assets used in the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7d6cc6",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "All needed libraries will be imported here.\n",
    "\n",
    "Unless conditional, all imports must be done in this section to prevent workspace cluttering. Imports are sorted in an ascending manner, starting from \"a\" to \"Z\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d134490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from copy import copy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.applications import VGG16, InceptionV3, ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import BatchNormalization, Dense, Dropout, Flatten, GlobalAveragePooling2D, Input, Resizing\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import datetime\n",
    "import gc\n",
    "import time\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdcf9cf",
   "metadata": {},
   "source": [
    "## Data and Variable\n",
    "\n",
    "Sets all the global data and variables here.\n",
    "\n",
    "Global variables will be defined and instantiated in this section, preventing a confusing clutter down the line and allowing readability when revisions are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d32c153",
   "metadata": {},
   "source": [
    "### Instantiations\n",
    "\n",
    "Instantiations of variables will be done here, preventing mixture of variable preview and definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3baad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    \"train\": {\n",
    "        \"raw\": [os.path.join('data', file) for file in os.listdir(\"data\") if file.startswith('data_batch_')],\n",
    "        \"loaded\": {},\n",
    "        \"processed\": None\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"raw\": os.path.join('data', 'test_batch'),\n",
    "        \"loaded\": {},\n",
    "        \"processed\": None\n",
    "    },\n",
    "    \"meta\": os.path.join('data', 'batches.meta')\n",
    "}\n",
    "\"\"\"\n",
    "A dictionary to hold the data for the CIFAR-10 dataset.\n",
    "The dictionary contains the following keys:\n",
    "\n",
    "- train: A dictionary containing the training data. It has two keys:\n",
    "    - raw: A list of file paths for the training data files.\n",
    "    - loaded: A dictionary to hold the loaded training data.\n",
    "    - processed: A dictionary to hold the processed training data.\n",
    "- test: A dictionary containing the test data. It has two keys:\n",
    "    - raw: The file path for the test data file.\n",
    "    - loaded: A dictionary to hold the loaded test data.\n",
    "    - processed: A dictionary to hold the processed test data.\n",
    "- meta: The file path for the metadata file.\n",
    "\n",
    ":var data: dict\n",
    "\"\"\"\n",
    "\n",
    "models = {\n",
    "    \"aliases\": {\n",
    "        VGG16.__name__: \"VGG16\",\n",
    "        InceptionV3.__name__: \"IV3\",\n",
    "        ResNet50.__name__: \"RN50\",\n",
    "\t},\n",
    "    \"configs\": {\n",
    "        \"VGG16\": [],\n",
    "\t\t\"IV3\": [],\n",
    "\t\t\"RN50\": [],\n",
    "\t},\n",
    "    \"fitted\": {\n",
    "        \"VGG16\": [],\n",
    "\t\t\"IV3\": [],\n",
    "\t\t\"RN50\": [],\n",
    "\t},\n",
    "    \"predictionResults\": {\n",
    "        \"VGG16\": [],\n",
    "\t\t\"IV3\": [],\n",
    "\t\t\"RN50\": [],\n",
    "\t}\n",
    "}\n",
    "\"\"\"\n",
    "A dictionary to hold the compiled and fitted models for transfer learning.\n",
    "The dictionary contains the following subkeys:\n",
    "\n",
    "- VGG16: The VGG16 model from Keras applications.\n",
    "- IV3: The InceptionV3 model from Keras applications.\n",
    "- RN50: The ResNet50 model from Keras applications.\n",
    "\n",
    "... for keys:\n",
    "\n",
    "- configs: A list to hold the model configurations.\n",
    "- fitted: A list to hold the fitted models.\n",
    "- predictionResults: A list to hold the prediction results.\n",
    "\n",
    "For reference; the `aliases` object is used to map the model names to their respective\n",
    "aliases for the three other 1st level keys. By simply using the model name (`model.__name__`),\n",
    "the model can be referenced in the other keys.\n",
    "\n",
    "Example:\n",
    "```\n",
    "alias = models[\"aliases\"][model.__name__]\n",
    "model = models[\"configs\"][alias][0]\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        patience = 10,\n",
    "        verbose = 2,\n",
    "        restore_best_weights = True\n",
    "    ),\n",
    "    # ReduceLROnPlateau(\n",
    "    #     monitor = 'val_loss',\n",
    "    #     factor = 0.5,\n",
    "    #     patience = 5,\n",
    "    #     verbose = 2,\n",
    "    #     min_lr = 1e-6\n",
    "    # )\n",
    "]\n",
    "\"\"\"\n",
    "A list of callbacks for the model training. Currently, it contains\n",
    "the following callbacks:\n",
    "- EarlyStopping: Stops training when a monitored metric has stopped improving.\n",
    "\"\"\"\n",
    "\n",
    "configCombinations = {\n",
    "\t'baseModel': [VGG16, InceptionV3, ResNet50],\n",
    "\t'trainBase': [True, False],\n",
    "\t'poolingLayer': [GlobalAveragePooling2D, Flatten],\n",
    "\t'dropoutRate': [0.3, 0.4, 0.5],\n",
    "\t'denseUnits': [512, 640, 768, 896],\n",
    "\t'useBatchNorm': [True, False],\n",
    "\t'hlDecayMode': ['l1', 'l2', 'l1_l2'],\n",
    "\t'hlDecayRate': [0.0001, 0.0005, 0.001],\n",
    "\t'opDecayMode': ['l1', 'l2', 'l1_l2'],\n",
    "\t'opDecayRate': [0.0001, 0.0005, 0.001],\n",
    "}\n",
    "\"\"\"\n",
    "A dictionary that holds all possible configuration combination values for `buildModel()`\n",
    "function.\n",
    "\"\"\"\n",
    "\n",
    "modelProfiler = []\n",
    "\"\"\"\n",
    "An empty list that will be used to store the training time of each model.\n",
    "\"\"\"\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43867cd3",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69f1f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unpickle(file):\n",
    "    \"\"\"\n",
    "    Decompiles a pickle file.\n",
    "\n",
    "    :param file: Path to the pickle file.\n",
    "    :type file: str\n",
    "    \n",
    "    :return: The unpickled data.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(file):\n",
    "        raise FileNotFoundError(f\"File {file} not found.\")\n",
    "    \n",
    "    with open(file, 'rb') as fo:\n",
    "        data = pickle.load(fo, encoding='bytes')\n",
    "    return data\n",
    "\n",
    "def unpickleToTuple(file):\n",
    "    \"\"\"\n",
    "    Decompiles a pickle file into a tuple. The tuple\n",
    "    contains the `data` and `labels` keys from the unpickled data\n",
    "    in that respective order.\n",
    "\n",
    "    The `data` key contains the image data and the `labels` key\n",
    "    contains the labels for the images.\n",
    "\n",
    "    The `data` key is a numpy array of shape (n, 3072) where n is the\n",
    "    number of images. The `labels` key is a list of length n containing\n",
    "    the labels for the images.\n",
    "\n",
    "    :param file: Path to the pickle file.\n",
    "    :type file: str\n",
    "    \n",
    "    :return: The unpickled data as a tuple.\n",
    "    :rtype: tuple\n",
    "    \"\"\"\n",
    "    data = unpickle(file)\n",
    "    return (data[b'data'], data[b'labels'])\n",
    "\n",
    "def showImg(input, title = None, axis = False):\n",
    "    \"\"\"\n",
    "    Displays an image.\n",
    "\n",
    "    :param input: The image to display.\n",
    "    :type input: numpy.ndarray\n",
    "    \n",
    "    :param title: Title of the image.\n",
    "    :type title: str\n",
    "\n",
    "    :param axis: Whether to show the axis or not.\n",
    "    :type axis: bool\n",
    "    \"\"\"\n",
    "    plt.imshow(input)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    if not axis:\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def buildModel(baseModel, trainBase = False, poolingLayer = GlobalAveragePooling2D, dropoutRate = 0.5, denseUnits = 512, useBatchNorm = True, hlDecayMode = 'l2', hlDecayRate = 0.001, opDecayMode = 'l2', opDecayRate = 0.001) -> Model:\n",
    "\t\"\"\"\n",
    "\tBuilds the model for transfer learning.\n",
    "\n",
    "\t:param baseModel: The base model to use for transfer learning. Required.\n",
    "\t:type baseModel: tensorflow.keras.applications.VGG16 | tensorflow.keras.applications.InceptionV3 | tensorflow.keras.applications.ResNet50\n",
    "\n",
    "\t:param trainBase: Whether to train the base model or not. Default is False.\n",
    "\t:type trainBase: bool\n",
    "\n",
    "\t:param dropoutRate: The dropout rate for the model. Default is 0.5.\n",
    "\t:type dropoutRate: float\n",
    "\n",
    "\t:param denseUnits: The number of units in the dense layer. Default is 512.\n",
    "\t:type denseUnits: int\n",
    "\n",
    "\t:param useBatchNorm: Whether to use batch normalization or not. Default is True.\n",
    "\t:type useBatchNorm: bool\n",
    "\n",
    "\t:hlDecayMode: The decay mode for the hidden layer. Default is 'l2'.\n",
    "\t:type hlDecayMode: 'l1', 'l2', 'l1_l2', 'none'\n",
    "\n",
    "\t:hlDecayRate: The decay rate for the hidden layer. Default is 0.001.\n",
    "\t:type hlDecayRate: float\n",
    "\n",
    "\t:opDecayMode: The decay mode for the output layer. Default is 'l2'.\n",
    "\t:type opDecayMode: 'l1', 'l2', 'l1_l2', 'none'\n",
    "\n",
    "\t:opDecayRate: The decay rate for the output layer. Default is 0.001.\n",
    "\t:type opDecayRate: float\n",
    "\n",
    "\t:return: The built model.\n",
    "\t:rtype: tensorflow.keras.models.Model\n",
    "\t\"\"\"\n",
    "\t# Guard check just to make sure the pooling layer won't kill my device...\n",
    "\t# Basically, it ensures that 'Flatten' is not used with models other than VGG16\n",
    "\tif poolingLayer is Flatten and baseModel is not VGG16:\n",
    "\t\tpoolingLayer = GlobalAveragePooling2D\n",
    "\n",
    "\t# Applies the resizing layer to the input shape\n",
    "\ttargetShape = (299, 299) if baseModel is InceptionV3 else (224, 224)\n",
    "\tinputTensor = Input(shape = (32, 32, 3))\n",
    "\tinputTensor = Resizing(*targetShape)(inputTensor)\n",
    "\tprint(\"Resizing Layer Shape: \", inputTensor.shape)\n",
    "\n",
    "\tbase = baseModel(weights = 'imagenet', include_top = False, input_tensor = inputTensor)\n",
    "\tprint(f\"Base model: {baseModel.__name__} - {base.output}\")\n",
    "\n",
    "\t# Freeze the base model layers (if True)\n",
    "\tbase.trainable = trainBase\n",
    "\n",
    "\tx = poolingLayer()(base.output)\n",
    "\tprint(f\"Pooling Layer Shape: {x.shape}\")\n",
    "\n",
    "\tif useBatchNorm:\n",
    "\t\tx = BatchNormalization()(x)\n",
    "\n",
    "\t# HIDDEN LAYER\n",
    "\t# By default, this looks like without the decays:\n",
    "\t#\tx = Dense(512, activation = \"relu\")(x)\n",
    "\thlKernelRegularizer = None\n",
    "\tif hlDecayMode in ('l1', 'l2', 'l1_l2') and hlDecayRate > 0:\n",
    "\t\tif hlDecayMode == 'l1':\n",
    "\t\t\thlKernelRegularizer = l1(hlDecayRate)\n",
    "\t\telif hlDecayMode == 'l2':\n",
    "\t\t\thlKernelRegularizer = l2(hlDecayRate)\n",
    "\t\telif hlDecayMode == 'l1_l2':\n",
    "\t\t\tif hlDecayRate is list:\n",
    "\t\t\t\thlKernelRegularizer = l1_l2(hlDecayRate[0], hlDecayRate[1])\n",
    "\t\t\telse:\n",
    "\t\t\t\thlKernelRegularizer = l1_l2(hlDecayRate, hlDecayRate)\n",
    "\tx = Dense(denseUnits, activation = \"relu\", kernel_regularizer = hlKernelRegularizer)(x)\n",
    "\n",
    "\tif useBatchNorm:\n",
    "\t\tx = BatchNormalization()(x)\n",
    "\n",
    "\tif dropoutRate > 0:\n",
    "\t\t# By default, this looks like:\n",
    "\t\t#\tx = Dropout(0.5)(x)\n",
    "\t\tx = Dropout(dropoutRate)(x)\n",
    "\n",
    "\t# OUTPUT LAYER\n",
    "\t# By default, this looks like without the decays:\n",
    "\t#\tx = Dense(10, activation = \"softmax\")(x)\n",
    "\topKernelRegularizer = None\n",
    "\tif opDecayMode in ('l1', 'l2', 'l1_l2') and opDecayRate > 0:\n",
    "\t\tif opDecayMode == 'l1':\n",
    "\t\t\topKernelRegularizer = l1(opDecayRate)\n",
    "\t\telif opDecayMode == 'l2':\n",
    "\t\t\topKernelRegularizer = l2(opDecayRate)\n",
    "\t\telif opDecayMode == 'l1_l2':\n",
    "\t\t\tif opDecayRate is list:\n",
    "\t\t\t\topKernelRegularizer = l1_l2(opDecayRate[0], opDecayRate[1])\n",
    "\t\t\telse:\n",
    "\t\t\t\topKernelRegularizer = l1_l2(opDecayRate, opDecayRate)\n",
    "\toutputs = Dense(10, activation = \"relu\", kernel_regularizer = opKernelRegularizer)(x)\n",
    "\n",
    "\treturn Model(inputs = inputTensor, outputs = outputs)\n",
    "\n",
    "def randomConfigSampler(possibleConfigValues, nSamples):\n",
    "\t\"\"\"\n",
    "\tSamples random configurations from the possible configuration values. The function is\n",
    "\tdesigned to generate a list of unique configurations, allowing for creating a diverse set of\n",
    "\tmodels for experimentation.\n",
    "\n",
    "\t:param popssibleConfigValues: The possible configuration values.\n",
    "\t:type popssibleConfigValues: dict\n",
    "\n",
    "\t:param nSamples: The number of samples to generate.\n",
    "\t:type nSamples: int\n",
    "\n",
    "\t:return: A list of random configurations.\n",
    "\t:rtype: list\n",
    "\t\"\"\"\n",
    "\tconfigs = []\n",
    "\tdefinedConfigs = set()\n",
    "\n",
    "\twhile len(configs) < nSamples:\n",
    "\t\tconfig = {}\n",
    " \n",
    "\t\t# Sample a random configuration\n",
    "\t\tfor key, value in possibleConfigValues.items():\n",
    "\t\t\tconfig[key] = random.choice(value)\n",
    "\n",
    "\t\t\tif key == 'poolingLayer':\n",
    "\t\t\t\t# Additional guard check just to make sure the pooling layer won't kill my device...\n",
    "\t\t\t\t# Basically, it ensures that 'Flatten' is not used with models other than VGG16\n",
    "\t\t\t\tif config[key] is Flatten and config['baseModel'] is not VGG16:\n",
    "\t\t\t\t\tconfig[key] = GlobalAveragePooling2D\n",
    "\n",
    "\t\t# Creates the input shape based on the base model\n",
    "\t\t# target_shape = (299, 299) if config['baseModel'] is InceptionV3 else (224, 224)\n",
    "\t\t# config['inputTensor'] = Input(shape = (*target_shape, 3))\n",
    "\n",
    "\t\tconfigTuple = tuple(sorted((k, v) for k, v in config.items() if k != 'inputTensor'))\n",
    "\n",
    "\t\t# Add the config to the list if unique\n",
    "\t\tif configTuple not in definedConfigs:\n",
    "\t\t\tdefinedConfigs.add(configTuple)\n",
    "\t\t\tconfigs.append(config)\n",
    "\t\t# If the config is not unique, try again\n",
    "\t\telse:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\treturn configs\n",
    "\n",
    "def preprocessImg(img, lbl, targetSize, augment = False):\n",
    "\t\"\"\"\n",
    "\tPreprocesses the image and label for training.\n",
    "\n",
    "\t:param img: The image to preprocess.\n",
    "\t:type img: numpy.ndarray\n",
    "\n",
    "\t:param lbl: The label to preprocess.\n",
    "\t:type lbl: int\n",
    "\n",
    "\t:param targetSize: The target size for the image.\n",
    "\t:type targetSize: tuple\n",
    "\n",
    "\t:param augment: Whether to augment the image or not. Default is False.\n",
    "\t:type augment: bool\n",
    "\n",
    "\t:return: The preprocessed image and label.\n",
    "\t:rtype: tuple\n",
    "\t\"\"\"\n",
    "\timg = tf.reshape(img, (32, 32, 3))\n",
    "\timg = tf.image.resize(img, targetSize)\n",
    "\timg = tf.cast(img, tf.float32) / 255.0\t\n",
    "\n",
    "\tif augment:\n",
    "\t\timg = tf.image.random_flip_left_right(img)\n",
    "\t\timg = tf.image.random_brightness(img, 0.2)\n",
    "\t\timg = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "\t\timg = tf.image.random_saturation(img, 0.8, 1.2)\n",
    "\t\timg = tf.image.random_hue(img, 0.08)\n",
    "\n",
    "\treturn img, lbl\n",
    "\n",
    "def makeDataset(x, y, targetSize, augment = False, batchSize = 15):\n",
    "\t\"\"\"\n",
    "\tCreates a TensorFlow dataset from the given data.\n",
    "\n",
    "\t:param x: The input data.\n",
    "\t:type x: numpy.ndarray\n",
    "\n",
    "\t:param y: The labels.\n",
    "\t:type y: numpy.ndarray\n",
    "\n",
    "\t:param targetSize: The target size for the images.\n",
    "\t:type targetSize: tuple\n",
    "\n",
    "\t:param augment: Whether to augment the images or not. Default is False.\n",
    "\t:type augment: bool\n",
    "\n",
    "\t:param batchSize: The batch size for the dataset. Default is 15.\n",
    "\t:type batchSize: int\n",
    "\t\"\"\"\n",
    "\tds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "\tds = ds.map(lambda img, label: preprocessImg(img, label, targetSize, augment),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\tif augment:\n",
    "\t\tds = ds.shuffle(10000)\n",
    "\tds = ds.batch(batchSize).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\treturn ds\n",
    "\n",
    "def getMetrics(model, dataset, logPerBatch = False):\n",
    "\t\"\"\"\n",
    "\tCalculates the accuracy `(avg)` and accuracy range `(min, max)`\n",
    "\tfor the given model and dataset.\n",
    "\n",
    "\tAlso returns the true labels and predicted labels. The metrics are all floats\n",
    "\tthat represent the score in decimal and not percentage.\n",
    "\n",
    "\t:param model: The model to use for prediction.\n",
    "\t:type model: tensorflow.keras.models.Model\n",
    "\n",
    "\t:param dataset: The dataset to calculate the metrics for.\n",
    "\t:type dataset: tensorflow.data.Dataset\n",
    "\n",
    "\t:param logPerBatch: Whether to log the metrics per batch or not. Default is False.\n",
    "\t:type logPerBatch: bool\n",
    "\n",
    "\t:return: A tuple containing metrics, the true labels, and the predicted labels; wherein the metrics is also a tuple containing the `(avg, min, max)` values.\n",
    "\t:rtype: tuple(tuple, list, list)\n",
    "\t\"\"\"\n",
    "\tmin = 0\n",
    "\tmax = 0\n",
    "\tavg = 0\n",
    "\n",
    "\tyTrue = []\n",
    "\tyPred = []\n",
    "\n",
    "\tfor x, y in dataset:\n",
    "\t\tclasses = model.predict(x, verbose = 0)\n",
    "\t\tclasses = np.argmax(classes, axis = 1)\n",
    "\n",
    "\t\tyTrue.extend(y)\n",
    "\t\tyPred.extend(classes)\n",
    "\n",
    "\t\tif logPerBatch:\n",
    "\t\t\tprint(f\"Classes: {classes}\")\n",
    "\t\t\tprint(f\"Labels: {y}\")\n",
    "\n",
    "\t\t# Accuracy\n",
    "\t\taccuracy = np.sum(classes == y) / len(y)\n",
    "\t\tif accuracy > max:\n",
    "\t\t\tmax = accuracy\n",
    "\t\tif accuracy < min or min == 0:\n",
    "\t\t\tmin = accuracy\n",
    "\t\tavg += accuracy\n",
    "\n",
    "\t\tif logPerBatch:\n",
    "\t\t\tprint(f\"Formula: {np.sum(classes == y)} / {len(y)}\")\n",
    "\t\t\tprint(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\t\t\tprint(f\"Of {len(y)} images, {np.sum(classes == y)} were correct while {np.sum(classes != y)} were incorrect.\")\n",
    "\n",
    "\tavg /= len(dataset)\n",
    "\treturn (avg, min, max), yTrue, yPred\n",
    "\n",
    "def plotModelHistory(modelName, history, accuracy, yTrue, yPred):\n",
    "\t\"\"\"\n",
    "\tPlots the training history of the model.\n",
    "\n",
    "\t:param modelName: The name of the model.\n",
    "\t:type modelName: str\n",
    "\n",
    "\t:param history: The training history of the model.\n",
    "\t:type history: tensorflow.keras.callbacks.History\n",
    "\n",
    "\t:param accuracy: The accuracy of the model in decimal form (not percentage).\n",
    "\t:type accuracy: float\n",
    "\n",
    "\t:param yTrue: The true labels of the dataset.\n",
    "\t:type yTrue: list\n",
    "\n",
    "\t:param yPred: The predicted labels of the dataset.\n",
    "\t:type yPred: list\n",
    "\t\"\"\"\n",
    "\tstatus = \"Underfitted\" if accuracy < 0.5 else \"Overfitted\" if accuracy > 0.9 else \"Just Right\"\n",
    "\tyTrue = np.sum(np.array(yTrue) == np.array(yPred))\n",
    "\tyLength = len(yPred)\n",
    "\tyScore = yTrue / yLength\n",
    "\n",
    "\taccuracy = accuracy * 100\n",
    "\tunixTime = int(datetime.datetime.now().timestamp() * 1e6)\n",
    "\n",
    "\tprint(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\tprint(f\"Using `forCM`: {yTrue} / {yLength} = {yScore * 100:.2f}%\")\n",
    "\n",
    "\tif not os.path.exists(f\"outputs/accuracy/{modelName}\"):\n",
    "\t\tos.makedirs(f\"outputs/accuracy/{modelName}\")\n",
    "\n",
    "\tplt.figure(figsize = (10, 6))\n",
    "\tplt.plot(history.history['accuracy'], color = 'blue', label = 'train')\n",
    "\tplt.plot(history.history['val_accuracy'], color = 'red', label = 'val')\n",
    "\tplt.legend()\n",
    "\tplt.grid()\n",
    "\tplt.title(f'Accuracy ({modelName})\\nStatus: {status} ({accuracy:.2f}%)')\n",
    "\tplt.xlabel('Epochs')\n",
    "\tplt.ylabel('Accuracy')\n",
    "\tplt.savefig(f\"outputs/accuracy/{modelName}/{unixTime} - {accuracy:.2f}%.png\")\n",
    "\n",
    "def plotConfusionMatrix(yTrue, yPred, modelName, accuracy):\n",
    "\t\"\"\"\n",
    "\tPlots the confusion matrix for the model predictions.\n",
    "\n",
    "\t:param yTrue: The true labels of the dataset.\n",
    "\t:type yTrue: list\n",
    "\n",
    "\t:param yPred: The predicted labels of the dataset.\n",
    "\t:type yPred: list\n",
    "\n",
    "\t:param modelName: The name of the model.\n",
    "\t:type modelName: str\n",
    "\n",
    "\t:param accuracy: The accuracy of the model in decimal form (not percentage).\n",
    "\t:type accuracy: float\n",
    "\t\"\"\"\n",
    "\tunixTime = int(datetime.datetime.now().timestamp() * 1e6)\n",
    "\tconfusion = confusion_matrix(yTrue, yPred)\n",
    "\n",
    "\tplt.figure(figsize = (10, 8))\n",
    "\tsns.heatmap(confusion, annot = True, fmt = 'd', cmap = 'Blues')\n",
    "\n",
    "\tplt.title('Confusion Matrix')\n",
    "\tplt.xlabel('Predicted Label')\n",
    "\tplt.ylabel('True Label')\n",
    "\n",
    "\tif not os.path.exists(f\"outputs/confusion_matrix/{modelName}\"):\n",
    "\t\tos.makedirs(f\"outputs/confusion_matrix/{modelName}\")\n",
    "\n",
    "\tplt.savefig(f\"outputs/confusion_matrix/{modelName}/{unixTime} - {accuracy:.2f}%.png\")\n",
    "\n",
    "def plotModel(model, accuracy, modelName = None):\n",
    "\t\"\"\"\n",
    "\tPlots the model architecture.\n",
    "\n",
    "\t:param model: The model to plot.\n",
    "\t:type model: tensorflow.keras.models.Model\n",
    "\n",
    "\t:param accuracy: The accuracy of the model in decimal form (not percentage).\n",
    "\t:type accuracy: float\n",
    "\n",
    "\t:param modelName: The name of the model. Optional.\n",
    "\t:type modelName: str\n",
    "\t\"\"\"\n",
    "\tif modelName is None:\n",
    "\t\tmodelName = model.__name__\n",
    "\n",
    "\tunixTime = int(datetime.datetime.now().timestamp() * 1e6)\n",
    "\tplot_model(model, to_file = f\"outputs/{modelName}_model_{unixTime} - {accuracy}%.png\", show_shapes = True, show_layer_names = True)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896bd0b3",
   "metadata": {},
   "source": [
    "### Previews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4cdf506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "870a4d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'baseModel': <function keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
       "  'trainBase': False,\n",
       "  'poolingLayer': keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D,\n",
       "  'dropoutRate': 0.5,\n",
       "  'denseUnits': 768,\n",
       "  'useBatchNorm': False,\n",
       "  'hlDecayMode': 'l1',\n",
       "  'hlDecayRate': 0.0001,\n",
       "  'opDecayMode': 'l2',\n",
       "  'opDecayRate': 0.001},\n",
       " {'baseModel': <function keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
       "  'trainBase': True,\n",
       "  'poolingLayer': keras.layers.reshaping.flatten.Flatten,\n",
       "  'dropoutRate': 0.3,\n",
       "  'denseUnits': 640,\n",
       "  'useBatchNorm': True,\n",
       "  'hlDecayMode': 'l1',\n",
       "  'hlDecayRate': 0.0005,\n",
       "  'opDecayMode': 'l1_l2',\n",
       "  'opDecayRate': 0.001},\n",
       " {'baseModel': <function keras.applications.inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
       "  'trainBase': False,\n",
       "  'poolingLayer': keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D,\n",
       "  'dropoutRate': 0.3,\n",
       "  'denseUnits': 512,\n",
       "  'useBatchNorm': False,\n",
       "  'hlDecayMode': 'l1_l2',\n",
       "  'hlDecayRate': 0.001,\n",
       "  'opDecayMode': 'l1',\n",
       "  'opDecayRate': 0.0005},\n",
       " {'baseModel': <function keras.applications.inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
       "  'trainBase': False,\n",
       "  'poolingLayer': keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D,\n",
       "  'dropoutRate': 0.4,\n",
       "  'denseUnits': 768,\n",
       "  'useBatchNorm': False,\n",
       "  'hlDecayMode': 'l2',\n",
       "  'hlDecayRate': 0.0001,\n",
       "  'opDecayMode': 'l2',\n",
       "  'opDecayRate': 0.001},\n",
       " {'baseModel': <function keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
       "  'trainBase': True,\n",
       "  'poolingLayer': keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D,\n",
       "  'dropoutRate': 0.5,\n",
       "  'denseUnits': 768,\n",
       "  'useBatchNorm': False,\n",
       "  'hlDecayMode': 'l1',\n",
       "  'hlDecayRate': 0.001,\n",
       "  'opDecayMode': 'l2',\n",
       "  'opDecayRate': 0.0005},\n",
       " {'baseModel': <function keras.applications.inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
       "  'trainBase': False,\n",
       "  'poolingLayer': keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D,\n",
       "  'dropoutRate': 0.4,\n",
       "  'denseUnits': 768,\n",
       "  'useBatchNorm': True,\n",
       "  'hlDecayMode': 'l1_l2',\n",
       "  'hlDecayRate': 0.0001,\n",
       "  'opDecayMode': 'l2',\n",
       "  'opDecayRate': 0.001},\n",
       " {'baseModel': <function keras.applications.inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
       "  'trainBase': False,\n",
       "  'poolingLayer': keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D,\n",
       "  'dropoutRate': 0.4,\n",
       "  'denseUnits': 640,\n",
       "  'useBatchNorm': True,\n",
       "  'hlDecayMode': 'l1',\n",
       "  'hlDecayRate': 0.0001,\n",
       "  'opDecayMode': 'l2',\n",
       "  'opDecayRate': 0.0005},\n",
       " {'baseModel': <function keras.applications.inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
       "  'trainBase': True,\n",
       "  'poolingLayer': keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D,\n",
       "  'dropoutRate': 0.5,\n",
       "  'denseUnits': 512,\n",
       "  'useBatchNorm': False,\n",
       "  'hlDecayMode': 'l1',\n",
       "  'hlDecayRate': 0.0005,\n",
       "  'opDecayMode': 'l2',\n",
       "  'opDecayRate': 0.0005},\n",
       " {'baseModel': <function keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
       "  'trainBase': True,\n",
       "  'poolingLayer': keras.layers.reshaping.flatten.Flatten,\n",
       "  'dropoutRate': 0.4,\n",
       "  'denseUnits': 640,\n",
       "  'useBatchNorm': True,\n",
       "  'hlDecayMode': 'l1',\n",
       "  'hlDecayRate': 0.0005,\n",
       "  'opDecayMode': 'l1_l2',\n",
       "  'opDecayRate': 0.001},\n",
       " {'baseModel': <function keras.applications.inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
       "  'trainBase': False,\n",
       "  'poolingLayer': keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D,\n",
       "  'dropoutRate': 0.3,\n",
       "  'denseUnits': 640,\n",
       "  'useBatchNorm': False,\n",
       "  'hlDecayMode': 'l2',\n",
       "  'hlDecayRate': 0.0005,\n",
       "  'opDecayMode': 'l1',\n",
       "  'opDecayRate': 0.0005}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomConfigSampler(configCombinations, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eecd0e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data files: ['data\\\\data_batch_1', 'data\\\\data_batch_2', 'data\\\\data_batch_3', 'data\\\\data_batch_4', 'data\\\\data_batch_5']\n",
      "Testing data file: data\\test_batch\n",
      "Meta data file: data\\batches.meta\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training data files: {data['train']['raw']}\")\n",
    "print(f\"Testing data file: {data['test']['raw']}\")\n",
    "print(f\"Meta data file: {data['meta']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a986b113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpickling data\\data_batch_1...\n",
      "Unpickled data\\data_batch_1 with keys: dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
      "Batch shape: (10000, 3072)\n",
      "Labels shape: 10000\n",
      "Batch size: 10000\n",
      "Batch content size: 3072\n",
      "Peek in the batch: [[ 59  43  50 ... 140  84  72]\n",
      " [154 126 105 ... 139 142 144]\n",
      " [255 253 253 ...  83  83  84]\n",
      " ...\n",
      " [ 71  60  74 ...  68  69  68]\n",
      " [250 254 211 ... 215 255 254]\n",
      " [ 62  61  60 ... 130 130 131]]\n",
      "Peek in the batch content: [87 83 83 ... 42 42 44]\n",
      "==============================================\n",
      "Unpickling data\\data_batch_2...\n",
      "Unpickled data\\data_batch_2 with keys: dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
      "Batch shape: (10000, 3072)\n",
      "Labels shape: 10000\n",
      "Batch size: 10000\n",
      "Batch content size: 3072\n",
      "Peek in the batch: [[ 35  27  25 ... 169 168 168]\n",
      " [ 20  20  18 ... 111  97  51]\n",
      " [116 115 155 ...  18  84 124]\n",
      " ...\n",
      " [127 139 155 ... 197 192 191]\n",
      " [190 200 208 ... 163 182 192]\n",
      " [177 174 182 ... 119 127 136]]\n",
      "Peek in the batch content: [68 65 60 ... 36 33 35]\n",
      "==============================================\n",
      "Unpickling data\\data_batch_3...\n",
      "Unpickled data\\data_batch_3 with keys: dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
      "Batch shape: (10000, 3072)\n",
      "Labels shape: 10000\n",
      "Batch size: 10000\n",
      "Batch content size: 3072\n",
      "Peek in the batch: [[ 26  17  13 ...  27  26  27]\n",
      " [ 94 101  95 ... 182 184 155]\n",
      " [183 158 166 ... 250 250 250]\n",
      " ...\n",
      " [175 200 207 ... 124  49  32]\n",
      " [ 28  59  67 ...  36  44  41]\n",
      " [ 62  40  61 ... 127 124 116]]\n",
      "Peek in the batch content: [255 255 255 ... 255 255 255]\n",
      "==============================================\n",
      "Unpickling data\\data_batch_4...\n",
      "Unpickled data\\data_batch_4 with keys: dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
      "Batch shape: (10000, 3072)\n",
      "Labels shape: 10000\n",
      "Batch size: 10000\n",
      "Batch content size: 3072\n",
      "Peek in the batch: [[178 178 178 ...  80  80  77]\n",
      " [ 29  22  25 ...  29  31  30]\n",
      " [ 36  33  21 ... 173 170 170]\n",
      " ...\n",
      " [167 164 151 ... 132 142 130]\n",
      " [ 45  46  46 ...  30  34  24]\n",
      " [235 239 239 ... 182 175 174]]\n",
      "Peek in the batch content: [26 44 38 ... 83 83 78]\n",
      "==============================================\n",
      "Unpickling data\\data_batch_5...\n",
      "Unpickled data\\data_batch_5 with keys: dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
      "Batch shape: (10000, 3072)\n",
      "Labels shape: 10000\n",
      "Batch size: 10000\n",
      "Batch content size: 3072\n",
      "Peek in the batch: [[255 252 253 ... 173 231 248]\n",
      " [127 126 127 ... 102 108 112]\n",
      " [116  64  19 ...   7   6   5]\n",
      " ...\n",
      " [ 35  40  42 ...  77  66  50]\n",
      " [189 186 185 ... 169 171 171]\n",
      " [229 236 234 ... 173 162 161]]\n",
      "Peek in the batch content: [94 93 93 ... 20 22 30]\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "for file in data['train'][\"raw\"]:\n",
    "    print(f\"Unpickling {file}...\")\n",
    "    batch = unpickle(file)\n",
    "    print(f\"Unpickled {file} with keys: {batch.keys()}\")\n",
    "    print(f\"Batch shape: {batch[b'data'].shape}\")\n",
    "    print(f\"Labels shape: {len(batch[b'labels'])}\")\n",
    "    print(f\"Batch size: {len(batch[b'data'])}\")\n",
    "    print(f\"Batch content size: {len(batch[b'data'][random.randint(0, len(batch[b'data']) - 1)])}\")\n",
    "    print(f\"Peek in the batch: {batch[b'data']}\")\n",
    "    print(f\"Peek in the batch content: {batch[b'data'][random.randint(0, len(batch[b'data']) - 1)]}\")\n",
    "    print(\"==============================================\")\n",
    "    data['train'][\"loaded\"][file] = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbbc812f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpickling data\\test_batch...\n",
      "Unpickled data\\test_batch with keys: dict_keys([b'batch_label', b'labels', b'data', b'filenames'])\n",
      "Batch shape: (10000, 3072)\n",
      "Labels shape: 10000\n",
      "Batch size: 10000\n",
      "Batch content size: 3072\n",
      "Peek in the batch: [[158 159 165 ... 124 129 110]\n",
      " [235 231 232 ... 178 191 199]\n",
      " [158 158 139 ...   8   3   7]\n",
      " ...\n",
      " [ 20  19  15 ...  50  53  47]\n",
      " [ 25  15  23 ...  80  81  80]\n",
      " [ 73  98  99 ...  94  58  26]]\n",
      "Peek in the batch content: [ 75  80  66 ... 255 255 255]\n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unpickling {data['test']['raw']}...\")\n",
    "batch = unpickle(data['test']['raw'])\n",
    "print(f\"Unpickled {data['test']['raw']} with keys: {batch.keys()}\")\n",
    "print(f\"Batch shape: {batch[b'data'].shape}\")\n",
    "print(f\"Labels shape: {len(batch[b'labels'])}\")\n",
    "print(f\"Batch size: {len(batch[b'data'])}\")\n",
    "print(f\"Batch content size: {len(batch[b'data'][random.randint(0, len(batch[b'data']) - 1)])}\")\n",
    "print(f\"Peek in the batch: {batch[b'data']}\")\n",
    "print(f\"Peek in the batch content: {batch[b'data'][random.randint(0, len(batch[b'data']) - 1)]}\")\n",
    "print(\"==============================================\")\n",
    "data['test'][\"loaded\"] = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef09a1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'num_cases_per_batch': 10000,\n",
       " b'label_names': [b'airplane',\n",
       "  b'automobile',\n",
       "  b'bird',\n",
       "  b'cat',\n",
       "  b'deer',\n",
       "  b'dog',\n",
       "  b'frog',\n",
       "  b'horse',\n",
       "  b'ship',\n",
       "  b'truck'],\n",
       " b'num_vis': 3072}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['meta'] = unpickle(data['meta'])\n",
    "data['meta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd7ff7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'batch_label': b'training batch 2 of 5',\n",
       " b'labels': [1,\n",
       "  6,\n",
       "  6,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  3,\n",
       "  6,\n",
       "  6,\n",
       "  5,\n",
       "  4,\n",
       "  8,\n",
       "  3,\n",
       "  2,\n",
       "  6,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  4,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  2,\n",
       "  7,\n",
       "  6,\n",
       "  9,\n",
       "  0,\n",
       "  4,\n",
       "  5,\n",
       "  7,\n",
       "  1,\n",
       "  6,\n",
       "  7,\n",
       "  9,\n",
       "  1,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  3,\n",
       "  7,\n",
       "  4,\n",
       "  7,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  4,\n",
       "  6,\n",
       "  6,\n",
       "  1,\n",
       "  4,\n",
       "  9,\n",
       "  2,\n",
       "  6,\n",
       "  4,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  6,\n",
       "  0,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  8,\n",
       "  8,\n",
       "  3,\n",
       "  9,\n",
       "  5,\n",
       "  7,\n",
       "  1,\n",
       "  9,\n",
       "  4,\n",
       "  7,\n",
       "  9,\n",
       "  1,\n",
       "  9,\n",
       "  7,\n",
       "  5,\n",
       "  2,\n",
       "  7,\n",
       "  3,\n",
       "  4,\n",
       "  8,\n",
       "  8,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  9,\n",
       "  2,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  6,\n",
       "  8,\n",
       "  8,\n",
       "  1,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  5,\n",
       "  4,\n",
       "  7,\n",
       "  1,\n",
       "  6,\n",
       "  6,\n",
       "  1,\n",
       "  6,\n",
       "  1,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  4,\n",
       "  6,\n",
       "  9,\n",
       "  5,\n",
       "  8,\n",
       "  7,\n",
       "  1,\n",
       "  9,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  7,\n",
       "  6,\n",
       "  9,\n",
       "  0,\n",
       "  4,\n",
       "  7,\n",
       "  1,\n",
       "  4,\n",
       "  3,\n",
       "  4,\n",
       "  3,\n",
       "  9,\n",
       "  8,\n",
       "  7,\n",
       "  0,\n",
       "  8,\n",
       "  3,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  8,\n",
       "  0,\n",
       "  9,\n",
       "  4,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  4,\n",
       "  2,\n",
       "  7,\n",
       "  1,\n",
       "  7,\n",
       "  0,\n",
       "  2,\n",
       "  9,\n",
       "  7,\n",
       "  9,\n",
       "  8,\n",
       "  6,\n",
       "  4,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  6,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  3,\n",
       "  9,\n",
       "  4,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  3,\n",
       "  9,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  8,\n",
       "  3,\n",
       "  3,\n",
       "  5,\n",
       "  6,\n",
       "  4,\n",
       "  0,\n",
       "  9,\n",
       "  6,\n",
       "  6,\n",
       "  5,\n",
       "  0,\n",
       "  6,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  9,\n",
       "  3,\n",
       "  4,\n",
       "  6,\n",
       "  0,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  7,\n",
       "  2,\n",
       "  6,\n",
       "  9,\n",
       "  6,\n",
       "  5,\n",
       "  4,\n",
       "  5,\n",
       "  4,\n",
       "  7,\n",
       "  7,\n",
       "  6,\n",
       "  8,\n",
       "  1,\n",
       "  5,\n",
       "  9,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  7,\n",
       "  1,\n",
       "  4,\n",
       "  6,\n",
       "  4,\n",
       "  2,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  3,\n",
       "  8,\n",
       "  9,\n",
       "  4,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  9,\n",
       "  6,\n",
       "  3,\n",
       "  3,\n",
       "  6,\n",
       "  9,\n",
       "  5,\n",
       "  7,\n",
       "  6,\n",
       "  9,\n",
       "  4,\n",
       "  2,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  8,\n",
       "  7,\n",
       "  5,\n",
       "  1,\n",
       "  8,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  2,\n",
       "  7,\n",
       "  4,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  8,\n",
       "  9,\n",
       "  8,\n",
       "  2,\n",
       "  8,\n",
       "  9,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  7,\n",
       "  4,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  4,\n",
       "  0,\n",
       "  8,\n",
       "  4,\n",
       "  3,\n",
       "  7,\n",
       "  9,\n",
       "  7,\n",
       "  7,\n",
       "  9,\n",
       "  3,\n",
       "  6,\n",
       "  9,\n",
       "  8,\n",
       "  1,\n",
       "  5,\n",
       "  9,\n",
       "  8,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  5,\n",
       "  1,\n",
       "  0,\n",
       "  6,\n",
       "  7,\n",
       "  3,\n",
       "  0,\n",
       "  9,\n",
       "  0,\n",
       "  7,\n",
       "  0,\n",
       "  4,\n",
       "  8,\n",
       "  8,\n",
       "  0,\n",
       "  7,\n",
       "  0,\n",
       "  3,\n",
       "  9,\n",
       "  0,\n",
       "  8,\n",
       "  6,\n",
       "  8,\n",
       "  7,\n",
       "  7,\n",
       "  6,\n",
       "  4,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  8,\n",
       "  0,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  1,\n",
       "  2,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  6,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  7,\n",
       "  8,\n",
       "  1,\n",
       "  7,\n",
       "  4,\n",
       "  9,\n",
       "  6,\n",
       "  9,\n",
       "  8,\n",
       "  1,\n",
       "  2,\n",
       "  6,\n",
       "  1,\n",
       "  8,\n",
       "  5,\n",
       "  3,\n",
       "  7,\n",
       "  4,\n",
       "  7,\n",
       "  1,\n",
       "  9,\n",
       "  2,\n",
       "  9,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  8,\n",
       "  2,\n",
       "  5,\n",
       "  2,\n",
       "  0,\n",
       "  6,\n",
       "  0,\n",
       "  8,\n",
       "  1,\n",
       "  4,\n",
       "  9,\n",
       "  2,\n",
       "  5,\n",
       "  8,\n",
       "  2,\n",
       "  5,\n",
       "  8,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  4,\n",
       "  8,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  1,\n",
       "  9,\n",
       "  7,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  4,\n",
       "  3,\n",
       "  2,\n",
       "  5,\n",
       "  3,\n",
       "  6,\n",
       "  5,\n",
       "  2,\n",
       "  8,\n",
       "  7,\n",
       "  2,\n",
       "  8,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  6,\n",
       "  8,\n",
       "  1,\n",
       "  4,\n",
       "  9,\n",
       "  7,\n",
       "  1,\n",
       "  4,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  8,\n",
       "  2,\n",
       "  1,\n",
       "  7,\n",
       "  6,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  7,\n",
       "  7,\n",
       "  9,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  4,\n",
       "  9,\n",
       "  2,\n",
       "  8,\n",
       "  1,\n",
       "  4,\n",
       "  4,\n",
       "  1,\n",
       "  2,\n",
       "  7,\n",
       "  5,\n",
       "  8,\n",
       "  5,\n",
       "  4,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  4,\n",
       "  7,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  9,\n",
       "  1,\n",
       "  7,\n",
       "  9,\n",
       "  2,\n",
       "  0,\n",
       "  4,\n",
       "  3,\n",
       "  7,\n",
       "  5,\n",
       "  9,\n",
       "  2,\n",
       "  3,\n",
       "  7,\n",
       "  3,\n",
       "  5,\n",
       "  6,\n",
       "  8,\n",
       "  2,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  6,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  5,\n",
       "  1,\n",
       "  9,\n",
       "  8,\n",
       "  4,\n",
       "  0,\n",
       "  3,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  1,\n",
       "  6,\n",
       "  9,\n",
       "  3,\n",
       "  1,\n",
       "  4,\n",
       "  8,\n",
       "  7,\n",
       "  4,\n",
       "  7,\n",
       "  5,\n",
       "  5,\n",
       "  8,\n",
       "  1,\n",
       "  0,\n",
       "  7,\n",
       "  7,\n",
       "  0,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  6,\n",
       "  5,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  9,\n",
       "  7,\n",
       "  4,\n",
       "  7,\n",
       "  6,\n",
       "  1,\n",
       "  3,\n",
       "  5,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  4,\n",
       "  1,\n",
       "  8,\n",
       "  7,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  6,\n",
       "  7,\n",
       "  9,\n",
       "  2,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  5,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  9,\n",
       "  2,\n",
       "  4,\n",
       "  4,\n",
       "  2,\n",
       "  3,\n",
       "  6,\n",
       "  5,\n",
       "  7,\n",
       "  5,\n",
       "  6,\n",
       "  0,\n",
       "  7,\n",
       "  5,\n",
       "  4,\n",
       "  4,\n",
       "  8,\n",
       "  0,\n",
       "  2,\n",
       "  4,\n",
       "  8,\n",
       "  3,\n",
       "  2,\n",
       "  8,\n",
       "  1,\n",
       "  4,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  8,\n",
       "  7,\n",
       "  9,\n",
       "  7,\n",
       "  2,\n",
       "  8,\n",
       "  9,\n",
       "  1,\n",
       "  2,\n",
       "  4,\n",
       "  1,\n",
       "  6,\n",
       "  5,\n",
       "  4,\n",
       "  3,\n",
       "  6,\n",
       "  6,\n",
       "  0,\n",
       "  8,\n",
       "  8,\n",
       "  4,\n",
       "  4,\n",
       "  1,\n",
       "  7,\n",
       "  1,\n",
       "  8,\n",
       "  8,\n",
       "  6,\n",
       "  1,\n",
       "  6,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  4,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  9,\n",
       "  9,\n",
       "  2,\n",
       "  4,\n",
       "  9,\n",
       "  8,\n",
       "  8,\n",
       "  6,\n",
       "  7,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  2,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  0,\n",
       "  6,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  8,\n",
       "  0,\n",
       "  8,\n",
       "  2,\n",
       "  7,\n",
       "  7,\n",
       "  0,\n",
       "  7,\n",
       "  8,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  4,\n",
       "  7,\n",
       "  5,\n",
       "  4,\n",
       "  9,\n",
       "  4,\n",
       "  2,\n",
       "  4,\n",
       "  8,\n",
       "  5,\n",
       "  6,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  8,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  7,\n",
       "  0,\n",
       "  1,\n",
       "  5,\n",
       "  0,\n",
       "  9,\n",
       "  6,\n",
       "  4,\n",
       "  4,\n",
       "  8,\n",
       "  3,\n",
       "  9,\n",
       "  5,\n",
       "  2,\n",
       "  5,\n",
       "  7,\n",
       "  4,\n",
       "  0,\n",
       "  7,\n",
       "  3,\n",
       "  0,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  2,\n",
       "  9,\n",
       "  5,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  9,\n",
       "  3,\n",
       "  3,\n",
       "  7,\n",
       "  1,\n",
       "  2,\n",
       "  6,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  9,\n",
       "  8,\n",
       "  0,\n",
       "  4,\n",
       "  4,\n",
       "  2,\n",
       "  5,\n",
       "  9,\n",
       "  3,\n",
       "  1,\n",
       "  7,\n",
       "  8,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  0,\n",
       "  7,\n",
       "  7,\n",
       "  5,\n",
       "  9,\n",
       "  0,\n",
       "  6,\n",
       "  3,\n",
       "  8,\n",
       "  6,\n",
       "  0,\n",
       "  3,\n",
       "  7,\n",
       "  1,\n",
       "  9,\n",
       "  6,\n",
       "  9,\n",
       "  6,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  9,\n",
       "  5,\n",
       "  2,\n",
       "  2,\n",
       "  5,\n",
       "  0,\n",
       "  8,\n",
       "  9,\n",
       "  2,\n",
       "  4,\n",
       "  3,\n",
       "  8,\n",
       "  0,\n",
       "  0,\n",
       "  7,\n",
       "  3,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  7,\n",
       "  1,\n",
       "  5,\n",
       "  6,\n",
       "  8,\n",
       "  7,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  9,\n",
       "  6,\n",
       "  9,\n",
       "  9,\n",
       "  5,\n",
       "  1,\n",
       "  2,\n",
       "  4,\n",
       "  5,\n",
       "  8,\n",
       "  6,\n",
       "  4,\n",
       "  1,\n",
       "  8,\n",
       "  6,\n",
       "  2,\n",
       "  3,\n",
       "  5,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  8,\n",
       "  4,\n",
       "  9,\n",
       "  4,\n",
       "  7,\n",
       "  9,\n",
       "  3,\n",
       "  0,\n",
       "  8,\n",
       "  3,\n",
       "  7,\n",
       "  9,\n",
       "  2,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  8,\n",
       "  4,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  7,\n",
       "  0,\n",
       "  7,\n",
       "  7,\n",
       "  4,\n",
       "  8,\n",
       "  4,\n",
       "  5,\n",
       "  7,\n",
       "  5,\n",
       "  9,\n",
       "  1,\n",
       "  3,\n",
       "  7,\n",
       "  2,\n",
       "  7,\n",
       "  7,\n",
       "  4,\n",
       "  6,\n",
       "  4,\n",
       "  7,\n",
       "  7,\n",
       "  0,\n",
       "  9,\n",
       "  1,\n",
       "  0,\n",
       "  5,\n",
       "  2,\n",
       "  9,\n",
       "  4,\n",
       "  2,\n",
       "  1,\n",
       "  8,\n",
       "  4,\n",
       "  7,\n",
       "  8,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  9,\n",
       "  7,\n",
       "  8,\n",
       "  3,\n",
       "  8,\n",
       "  6,\n",
       "  5,\n",
       "  6,\n",
       "  8,\n",
       "  5,\n",
       "  4,\n",
       "  2,\n",
       "  7,\n",
       "  8,\n",
       "  3,\n",
       "  9,\n",
       "  3,\n",
       "  7,\n",
       "  2,\n",
       "  9,\n",
       "  2,\n",
       "  6,\n",
       "  3,\n",
       "  6,\n",
       "  6,\n",
       "  2,\n",
       "  9,\n",
       "  3,\n",
       "  9,\n",
       "  2,\n",
       "  5,\n",
       "  6,\n",
       "  4,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  8,\n",
       "  7,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  6,\n",
       "  8,\n",
       "  1,\n",
       "  1,\n",
       "  8,\n",
       "  4,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  9,\n",
       "  4,\n",
       "  8,\n",
       "  8,\n",
       "  2,\n",
       "  1,\n",
       "  5,\n",
       "  4,\n",
       "  8,\n",
       "  3,\n",
       "  4,\n",
       "  9,\n",
       "  6,\n",
       "  6,\n",
       "  8,\n",
       "  0,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  7,\n",
       "  5,\n",
       "  9,\n",
       "  8,\n",
       "  7,\n",
       "  3,\n",
       "  ...],\n",
       " b'data': array([[ 35,  27,  25, ..., 169, 168, 168],\n",
       "        [ 20,  20,  18, ..., 111,  97,  51],\n",
       "        [116, 115, 155, ...,  18,  84, 124],\n",
       "        ...,\n",
       "        [127, 139, 155, ..., 197, 192, 191],\n",
       "        [190, 200, 208, ..., 163, 182, 192],\n",
       "        [177, 174, 182, ..., 119, 127, 136]], dtype=uint8),\n",
       " b'filenames': [b'auto_s_000241.png',\n",
       "  b'bufo_viridis_s_001109.png',\n",
       "  b'rana_catesbeiana_s_000111.png',\n",
       "  b'banana_boat_s_000728.png',\n",
       "  b'powerboat_s_001487.png',\n",
       "  b'felis_catus_s_001376.png',\n",
       "  b'wapiti_s_001127.png',\n",
       "  b'goliath_frog_s_000230.png',\n",
       "  b'stealth_fighter_s_000898.png',\n",
       "  b'bullfrog_s_001623.png',\n",
       "  b'stealth_fighter_s_001883.png',\n",
       "  b'mouser_s_001482.png',\n",
       "  b'bufo_marinus_s_001427.png',\n",
       "  b'grass_frog_s_000425.png',\n",
       "  b'puppy_s_002462.png',\n",
       "  b'cervus_elaphus_s_001192.png',\n",
       "  b'cargo_ship_s_000773.png',\n",
       "  b'mouser_s_000261.png',\n",
       "  b'dunnock_s_000201.png',\n",
       "  b'western_toad_s_000205.png',\n",
       "  b'monoplane_s_001332.png',\n",
       "  b'felis_catus_s_000759.png',\n",
       "  b'car_s_000162.png',\n",
       "  b'wapiti_s_000018.png',\n",
       "  b'airbus_s_000239.png',\n",
       "  b'bufo_calamita_s_000786.png',\n",
       "  b'bufo_marinus_s_000662.png',\n",
       "  b'bird_of_passage_s_000631.png',\n",
       "  b'quarter_horse_s_001265.png',\n",
       "  b'toad_s_000581.png',\n",
       "  b'truck_s_000097.png',\n",
       "  b'propeller_plane_s_000916.png',\n",
       "  b'cervus_elaphus_s_001222.png',\n",
       "  b'puppy_s_000002.png',\n",
       "  b'cow_pony_s_000969.png',\n",
       "  b'compact_s_001620.png',\n",
       "  b'bufo_viridis_s_001555.png',\n",
       "  b'lippizaner_s_001231.png',\n",
       "  b'wrecker_s_002157.png',\n",
       "  b'compact_car_s_001251.png',\n",
       "  b'tennessee_walking_horse_s_001170.png',\n",
       "  b'lippizan_s_000636.png',\n",
       "  b'freighter_s_000979.png',\n",
       "  b'amphibious_aircraft_s_000663.png',\n",
       "  b'tabby_cat_s_002222.png',\n",
       "  b'appaloosa_s_002289.png',\n",
       "  b'capreolus_capreolus_s_000070.png',\n",
       "  b'arabian_s_000556.png',\n",
       "  b'tabby_s_001603.png',\n",
       "  b'motorcar_s_001303.png',\n",
       "  b'jumbo_jet_s_000933.png',\n",
       "  b'roe_deer_s_000960.png',\n",
       "  b'true_frog_s_000016.png',\n",
       "  b'toad_frog_s_001504.png',\n",
       "  b'auto_s_000857.png',\n",
       "  b'cervus_elaphus_s_001601.png',\n",
       "  b'garbage_truck_s_000150.png',\n",
       "  b'cassowary_s_002010.png',\n",
       "  b'leopard_frog_s_000836.png',\n",
       "  b'elk_s_001314.png',\n",
       "  b'puppy_s_000166.png',\n",
       "  b'stealth_fighter_s_000006.png',\n",
       "  b'moose_s_000441.png',\n",
       "  b'bufo_marinus_s_001074.png',\n",
       "  b'airbus_s_001326.png',\n",
       "  b'oil_tanker_s_001156.png',\n",
       "  b'domestic_cat_s_001862.png',\n",
       "  b'cervus_unicolor_s_000291.png',\n",
       "  b'cabin_cruiser_s_000515.png',\n",
       "  b'pontoon_s_000650.png',\n",
       "  b'cat_s_002274.png',\n",
       "  b'camion_s_001750.png',\n",
       "  b'pekingese_s_000627.png',\n",
       "  b'dawn_horse_s_001452.png',\n",
       "  b'station_wagon_s_002719.png',\n",
       "  b'car_transporter_s_001591.png',\n",
       "  b'capreolus_capreolus_s_000022.png',\n",
       "  b'buckskin_s_000377.png',\n",
       "  b'trucking_rig_s_001476.png',\n",
       "  b'automobile_s_000657.png',\n",
       "  b'delivery_truck_s_000818.png',\n",
       "  b'dawn_horse_s_001797.png',\n",
       "  b'toy_spaniel_s_001039.png',\n",
       "  b'emu_s_001451.png',\n",
       "  b'quarter_horse_s_001745.png',\n",
       "  b'tomcat_s_001296.png',\n",
       "  b'barking_deer_s_000704.png',\n",
       "  b'pilot_boat_s_001262.png',\n",
       "  b'pontoon_s_000122.png',\n",
       "  b'emu_novaehollandiae_s_000739.png',\n",
       "  b'automobile_s_002678.png',\n",
       "  b'pekingese_s_000604.png',\n",
       "  b'articulated_lorry_s_000837.png',\n",
       "  b'flying_bird_s_000765.png',\n",
       "  b'appaloosa_s_001709.png',\n",
       "  b'iceboat_s_001090.png',\n",
       "  b'hospital_ship_s_000995.png',\n",
       "  b'barking_frog_s_000663.png',\n",
       "  b'lightship_s_000644.png',\n",
       "  b'packet_boat_s_001152.png',\n",
       "  b'convertible_s_002167.png',\n",
       "  b'felis_catus_s_000620.png',\n",
       "  b'pilot_boat_s_001473.png',\n",
       "  b'cabin_cruiser_s_001798.png',\n",
       "  b'mutt_s_000956.png',\n",
       "  b'rangifer_tarandus_s_000618.png',\n",
       "  b'walking_horse_s_001400.png',\n",
       "  b'shooting_brake_s_000438.png',\n",
       "  b'bufo_bufo_s_001725.png',\n",
       "  b'pickerel_frog_s_000167.png',\n",
       "  b'convertible_s_001702.png',\n",
       "  b'ribbed_toad_s_000010.png',\n",
       "  b'coupe_s_001806.png',\n",
       "  b'bufo_bufo_s_001163.png',\n",
       "  b'male_horse_s_000117.png',\n",
       "  b'attack_aircraft_s_000376.png',\n",
       "  b'japanese_deer_s_000162.png',\n",
       "  b'spadefoot_s_000278.png',\n",
       "  b'moving_van_s_001355.png',\n",
       "  b'domestic_dog_s_001267.png',\n",
       "  b'passenger_ship_s_001219.png',\n",
       "  b'tennessee_walking_horse_s_000958.png',\n",
       "  b'car_s_001317.png',\n",
       "  b'lorry_s_000757.png',\n",
       "  b'dive_bomber_s_001252.png',\n",
       "  b'tomcat_s_001415.png',\n",
       "  b'mouser_s_000391.png',\n",
       "  b'stud_mare_s_000209.png',\n",
       "  b'spring_frog_s_000799.png',\n",
       "  b'trucking_rig_s_001492.png',\n",
       "  b'jumbo_jet_s_000280.png',\n",
       "  b'deer_s_001228.png',\n",
       "  b'lippizaner_s_000032.png',\n",
       "  b'shooting_brake_s_000073.png',\n",
       "  b'wapiti_s_000356.png',\n",
       "  b'tabby_cat_s_000371.png',\n",
       "  b'odocoileus_hemionus_s_000337.png',\n",
       "  b'felis_domesticus_s_000233.png',\n",
       "  b'delivery_truck_s_001202.png',\n",
       "  b'boat_s_001495.png',\n",
       "  b'dawn_horse_s_001521.png',\n",
       "  b'airbus_s_001258.png',\n",
       "  b'passenger_ship_s_001911.png',\n",
       "  b'felis_catus_s_001518.png',\n",
       "  b'garbage_truck_s_002301.png',\n",
       "  b'motorcar_s_001039.png',\n",
       "  b'fighter_aircraft_s_001264.png',\n",
       "  b'pontoon_s_002448.png',\n",
       "  b'twinjet_s_000885.png',\n",
       "  b'dump_truck_s_000843.png',\n",
       "  b'american_elk_s_000348.png',\n",
       "  b'jumbo_jet_s_000015.png',\n",
       "  b'pipit_s_001600.png',\n",
       "  b'station_wagon_s_001325.png',\n",
       "  b'american_elk_s_000918.png',\n",
       "  b'wagtail_s_000492.png',\n",
       "  b'lippizan_s_000511.png',\n",
       "  b'auto_s_001401.png',\n",
       "  b'lippizaner_s_001457.png',\n",
       "  b'stealth_bomber_s_000320.png',\n",
       "  b'night_bird_s_000013.png',\n",
       "  b'tandem_trailer_s_000307.png',\n",
       "  b'male_horse_s_000483.png',\n",
       "  b'delivery_van_s_001434.png',\n",
       "  b'police_boat_s_000283.png',\n",
       "  b'bufo_viridis_s_000043.png',\n",
       "  b'woodland_caribou_s_000358.png',\n",
       "  b'mule_deer_s_000471.png',\n",
       "  b'compact_car_s_002133.png',\n",
       "  b'coupe_s_000795.png',\n",
       "  b'tennessee_walking_horse_s_001113.png',\n",
       "  b'fireboat_s_000225.png',\n",
       "  b'passenger_ship_s_000841.png',\n",
       "  b'leopard_frog_s_002116.png',\n",
       "  b'alces_alces_s_000982.png',\n",
       "  b'chihuahua_s_000587.png',\n",
       "  b'bufo_viridis_s_000858.png',\n",
       "  b'tabby_cat_s_000033.png',\n",
       "  b'wrecker_s_001851.png',\n",
       "  b'capreolus_capreolus_s_000455.png',\n",
       "  b'songbird_s_001109.png',\n",
       "  b'lapdog_s_000838.png',\n",
       "  b'cat_s_000061.png',\n",
       "  b'bullfrog_s_001107.png',\n",
       "  b'stud_mare_s_001327.png',\n",
       "  b'lipizzan_s_001330.png',\n",
       "  b'cat_s_000443.png',\n",
       "  b'truck_s_001247.png',\n",
       "  b'convertible_s_000501.png',\n",
       "  b'mouser_s_001999.png',\n",
       "  b'station_wagon_s_002086.png',\n",
       "  b'liner_s_000093.png',\n",
       "  b'mouser_s_001487.png',\n",
       "  b'house_cat_s_000846.png',\n",
       "  b'pekingese_s_000508.png',\n",
       "  b'american_toad_s_001259.png',\n",
       "  b'sika_s_001341.png',\n",
       "  b'jumbo_jet_s_001427.png',\n",
       "  b'tipper_lorry_s_000666.png',\n",
       "  b'leopard_frog_s_001728.png',\n",
       "  b'bufo_boreas_s_000132.png',\n",
       "  b'maltese_s_000269.png',\n",
       "  b'monoplane_s_000748.png',\n",
       "  b'bufo_bufo_s_000201.png',\n",
       "  b'lark_s_000516.png',\n",
       "  b'dive_bomber_s_000841.png',\n",
       "  b'maltese_s_001525.png',\n",
       "  b'caribou_s_000653.png',\n",
       "  b'garbage_truck_s_000863.png',\n",
       "  b'mouser_s_001828.png',\n",
       "  b'mule_deer_s_000552.png',\n",
       "  b'bufo_americanus_s_001160.png',\n",
       "  b'biplane_s_001709.png',\n",
       "  b'toad_s_000260.png',\n",
       "  b'quarter_horse_s_001626.png',\n",
       "  b'jetliner_s_001710.png',\n",
       "  b'broodmare_s_001560.png',\n",
       "  b'cassowary_s_001496.png',\n",
       "  b'rana_pipiens_s_000928.png',\n",
       "  b'tipper_s_001582.png',\n",
       "  b'western_toad_s_000823.png',\n",
       "  b'canis_familiaris_s_000752.png',\n",
       "  b'dama_dama_s_000031.png',\n",
       "  b'peke_s_000621.png',\n",
       "  b'cervus_elaphus_s_000141.png',\n",
       "  b'lipizzan_s_001744.png',\n",
       "  b'lippizan_s_001018.png',\n",
       "  b'bufo_debilis_s_000136.png',\n",
       "  b'supertanker_s_001386.png',\n",
       "  b'coupe_s_000068.png',\n",
       "  b'domestic_dog_s_001353.png',\n",
       "  b'dump_truck_s_001642.png',\n",
       "  b'appaloosa_s_001996.png',\n",
       "  b'police_boat_s_000696.png',\n",
       "  b'police_boat_s_001924.png',\n",
       "  b'dawn_horse_s_001153.png',\n",
       "  b'minicab_s_000456.png',\n",
       "  b'red_deer_s_002795.png',\n",
       "  b'rana_pipiens_s_000894.png',\n",
       "  b'odocoileus_hemionus_s_000827.png',\n",
       "  b'songbird_s_000775.png',\n",
       "  b'ostrich_s_000676.png',\n",
       "  b'toy_spaniel_s_001041.png',\n",
       "  b'airliner_s_000086.png',\n",
       "  b'tabby_cat_s_000313.png',\n",
       "  b'hospital_ship_s_001233.png',\n",
       "  b'camion_s_000397.png',\n",
       "  b'deer_s_000022.png',\n",
       "  b'coupe_s_001631.png',\n",
       "  b'shooting_brake_s_000205.png',\n",
       "  b'fallow_deer_s_001929.png',\n",
       "  b'automobile_s_000018.png',\n",
       "  b'tipper_truck_s_000958.png',\n",
       "  b'rana_temporaria_s_001280.png',\n",
       "  b'alley_cat_s_002108.png',\n",
       "  b'true_cat_s_001819.png',\n",
       "  b'bufo_s_001805.png',\n",
       "  b'tipper_truck_s_001414.png',\n",
       "  b'puppy_s_000989.png',\n",
       "  b'walking_horse_s_000183.png',\n",
       "  b'bufo_viridis_s_001251.png',\n",
       "  b'delivery_truck_s_000214.png',\n",
       "  b'deer_s_001548.png',\n",
       "  b'cassowary_s_002283.png',\n",
       "  b'fawn_s_000239.png',\n",
       "  b'twinjet_s_000784.png',\n",
       "  b'airliner_s_002282.png',\n",
       "  b'biplane_s_000323.png',\n",
       "  b'tanker_s_000930.png',\n",
       "  b'gelding_s_001414.png',\n",
       "  b'pekinese_s_001157.png',\n",
       "  b'coupe_s_001112.png',\n",
       "  b'cargo_ship_s_002177.png',\n",
       "  b'western_toad_s_000670.png',\n",
       "  b'lippizan_s_000580.png',\n",
       "  b'biplane_s_001054.png',\n",
       "  b'convertible_s_000276.png',\n",
       "  b'broodmare_s_000060.png',\n",
       "  b'arabian_s_001837.png',\n",
       "  b'boat_s_000867.png',\n",
       "  b'rhea_americana_s_000531.png',\n",
       "  b'tennessee_walker_s_000900.png',\n",
       "  b'elk_s_000494.png',\n",
       "  b'container_ship_s_002232.png',\n",
       "  b'packet_boat_s_001294.png',\n",
       "  b'dump_truck_s_000454.png',\n",
       "  b'motorboat_s_001723.png',\n",
       "  b'camion_s_000388.png',\n",
       "  b'dredger_s_001572.png',\n",
       "  b'nandu_s_000417.png',\n",
       "  b'merchant_ship_s_001336.png',\n",
       "  b'ladder_truck_s_001340.png',\n",
       "  b'coupe_s_000484.png',\n",
       "  b'mouser_s_002051.png',\n",
       "  b'toy_dog_s_000018.png',\n",
       "  b'stud_mare_s_000579.png',\n",
       "  b'mule_deer_s_000232.png',\n",
       "  b'stealth_fighter_s_000503.png',\n",
       "  b'auto_s_001159.png',\n",
       "  b'caribou_s_000914.png',\n",
       "  b'dama_dama_s_000093.png',\n",
       "  b'fighter_aircraft_s_001775.png',\n",
       "  b'cabin_cruiser_s_000536.png',\n",
       "  b'sambar_s_000598.png',\n",
       "  b'tabby_cat_s_000028.png',\n",
       "  b'lippizaner_s_000618.png',\n",
       "  b'tipper_s_001725.png',\n",
       "  b'tennessee_walking_horse_s_000883.png',\n",
       "  b'lippizaner_s_001304.png',\n",
       "  b'dumper_s_000902.png',\n",
       "  b'mouser_s_000687.png',\n",
       "  b'grass_frog_s_001422.png',\n",
       "  b'delivery_truck_s_000518.png',\n",
       "  b'sea_boat_s_001030.png',\n",
       "  b'auto_s_001905.png',\n",
       "  b'chihuahua_s_000261.png',\n",
       "  b'tipper_s_001623.png',\n",
       "  b'cargo_ship_s_002279.png',\n",
       "  b'pekinese_s_001261.png',\n",
       "  b'japanese_spaniel_s_000623.png',\n",
       "  b'cat_s_000862.png',\n",
       "  b'felis_domesticus_s_000421.png',\n",
       "  b'tabby_s_000720.png',\n",
       "  b'stealth_fighter_s_000941.png',\n",
       "  b'chihuahua_s_000464.png',\n",
       "  b'taxi_s_001861.png',\n",
       "  b'airliner_s_001018.png',\n",
       "  b'leopard_frog_s_001685.png',\n",
       "  b'dawn_horse_s_001935.png',\n",
       "  b'cat_s_001667.png',\n",
       "  b'fighter_aircraft_s_001784.png',\n",
       "  b'garbage_truck_s_001523.png',\n",
       "  b'airbus_s_001593.png',\n",
       "  b'lipizzan_s_000113.png',\n",
       "  b'airliner_s_000861.png',\n",
       "  b'woodland_caribou_s_001564.png',\n",
       "  b'cargo_ship_s_000531.png',\n",
       "  b'oil_tanker_s_001388.png',\n",
       "  b'dive_bomber_s_000574.png',\n",
       "  b'tennessee_walking_horse_s_000707.png',\n",
       "  b'airliner_s_001754.png',\n",
       "  b'alley_cat_s_002692.png',\n",
       "  b'delivery_truck_s_000580.png',\n",
       "  b'twinjet_s_000837.png',\n",
       "  b'pleasure_craft_s_000039.png',\n",
       "  b'bufo_marinus_s_001124.png',\n",
       "  b'motorboat_s_000553.png',\n",
       "  b'quarter_horse_s_001294.png',\n",
       "  b'broodmare_s_000745.png',\n",
       "  b'bufo_debilis_s_000050.png',\n",
       "  b'fawn_s_000447.png',\n",
       "  b'camion_s_001322.png',\n",
       "  b'convertible_s_000135.png',\n",
       "  b'monoplane_s_001322.png',\n",
       "  b'river_boat_s_000575.png',\n",
       "  b'amphibious_aircraft_s_000449.png',\n",
       "  b'bufo_bufo_s_000283.png',\n",
       "  b'toad_s_002214.png',\n",
       "  b'appaloosa_s_002066.png',\n",
       "  b'automobile_s_001886.png',\n",
       "  b'accentor_s_000162.png',\n",
       "  b'cargo_ship_s_001208.png',\n",
       "  b'motorcar_s_000344.png',\n",
       "  b'shooting_brake_s_000489.png',\n",
       "  b'crapaud_s_002014.png',\n",
       "  b'stealth_fighter_s_000157.png',\n",
       "  b'pekingese_s_000639.png',\n",
       "  b'stag_s_002020.png',\n",
       "  b'dawn_horse_s_000959.png',\n",
       "  b'passenger_ship_s_001906.png',\n",
       "  b'wagon_s_000460.png',\n",
       "  b'broodmare_s_000596.png',\n",
       "  b'rangifer_caribou_s_000200.png',\n",
       "  b'delivery_truck_s_000415.png',\n",
       "  b'frog_s_000639.png',\n",
       "  b'dump_truck_s_000049.png',\n",
       "  b'container_ship_s_002511.png',\n",
       "  b'automobile_s_001372.png',\n",
       "  b'bird_s_000889.png',\n",
       "  b'bufo_bufo_s_001655.png',\n",
       "  b'police_cruiser_s_000367.png',\n",
       "  b'containership_s_000986.png',\n",
       "  b'pekingese_s_000544.png',\n",
       "  b'true_cat_s_000440.png',\n",
       "  b'lipizzan_s_000321.png',\n",
       "  b'moose_s_000424.png',\n",
       "  b'lipizzan_s_001657.png',\n",
       "  b'automobile_s_000444.png',\n",
       "  b'tipper_truck_s_000420.png',\n",
       "  b'meadow_pipit_s_000216.png',\n",
       "  b'truck_s_000039.png',\n",
       "  b'cassowary_s_000253.png',\n",
       "  b'american_elk_s_000027.png',\n",
       "  b'auto_s_000624.png',\n",
       "  b'stealth_fighter_s_000237.png',\n",
       "  b'icebreaker_s_000805.png',\n",
       "  b'night_bird_s_000242.png',\n",
       "  b'maltese_s_000168.png',\n",
       "  b'ostrich_s_000723.png',\n",
       "  b'seaplane_s_000836.png',\n",
       "  b'bufo_viridis_s_000161.png',\n",
       "  b'fighter_aircraft_s_000004.png',\n",
       "  b'passenger_ship_s_002168.png',\n",
       "  b'motorcar_s_001995.png',\n",
       "  b'rangifer_tarandus_s_000387.png',\n",
       "  b'aerial_ladder_truck_s_000785.png',\n",
       "  b'rhea_americana_s_000738.png',\n",
       "  b'mongrel_s_001913.png',\n",
       "  b'pleasure_craft_s_002049.png',\n",
       "  b'alauda_arvensis_s_000105.png',\n",
       "  b'maltese_dog_s_000038.png',\n",
       "  b'passenger_ship_s_002049.png',\n",
       "  b'pterocnemia_pennata_s_000074.png',\n",
       "  b'maltese_s_000121.png',\n",
       "  b'mouser_s_000393.png',\n",
       "  b'dama_dama_s_000602.png',\n",
       "  b'police_boat_s_002281.png',\n",
       "  b'emu_novaehollandiae_s_000248.png',\n",
       "  b'tabby_s_000316.png',\n",
       "  b'woodland_caribou_s_000606.png',\n",
       "  b'compact_car_s_000603.png',\n",
       "  b'moving_van_s_002137.png',\n",
       "  b'arabian_s_002039.png',\n",
       "  b'chihuahua_s_000386.png',\n",
       "  b'peke_s_001606.png',\n",
       "  b'jetliner_s_000504.png',\n",
       "  b'american_elk_s_000158.png',\n",
       "  b'cat_s_001613.png',\n",
       "  b'passerine_s_000623.png',\n",
       "  b'cur_s_000599.png',\n",
       "  b'tabby_s_001915.png',\n",
       "  b'pickerel_frog_s_000482.png',\n",
       "  b'king_charles_spaniel_s_000091.png',\n",
       "  b'dunnock_s_000723.png',\n",
       "  b'powerboat_s_000454.png',\n",
       "  b'lipizzan_s_001545.png',\n",
       "  b'wagtail_s_000481.png',\n",
       "  b'boat_s_002646.png',\n",
       "  b'ostrich_s_001069.png',\n",
       "  b'tabby_s_001430.png',\n",
       "  b'prunella_modularis_s_000012.png',\n",
       "  b'tabby_cat_s_000503.png',\n",
       "  b'police_boat_s_000738.png',\n",
       "  b'scow_s_001371.png',\n",
       "  b'toad_s_001837.png',\n",
       "  b'merchant_ship_s_000299.png',\n",
       "  b'compact_s_001674.png',\n",
       "  b'american_elk_s_000403.png',\n",
       "  b'trucking_rig_s_001164.png',\n",
       "  b'appaloosa_s_002310.png',\n",
       "  b'estate_car_s_000936.png',\n",
       "  b'deer_s_001765.png',\n",
       "  b'domestic_cat_s_001562.png',\n",
       "  b'car_s_000050.png',\n",
       "  b'felis_catus_s_000359.png',\n",
       "  b'twinjet_s_000676.png',\n",
       "  b'pleasure_boat_s_000607.png',\n",
       "  b'ostrich_s_002029.png',\n",
       "  b'coupe_s_001321.png',\n",
       "  b'lipizzan_s_000104.png',\n",
       "  b'bufo_bufo_s_002425.png',\n",
       "  b'bird_s_001444.png',\n",
       "  b'cat_s_001554.png',\n",
       "  b'cat_s_002076.png',\n",
       "  b'felis_domesticus_s_000194.png',\n",
       "  b'arabian_s_001015.png',\n",
       "  b'lippizaner_s_000679.png',\n",
       "  b'fire_truck_s_002190.png',\n",
       "  b'felis_domesticus_s_000135.png',\n",
       "  b'prunella_modularis_s_000196.png',\n",
       "  b'jumbo_jet_s_001188.png',\n",
       "  b'pekingese_s_000096.png',\n",
       "  b'rangifer_caribou_s_000023.png',\n",
       "  b'car_transporter_s_000146.png',\n",
       "  b'bird_s_001435.png',\n",
       "  b'mackinaw_boat_s_000446.png',\n",
       "  b'coupe_s_000582.png',\n",
       "  b'moose_s_000061.png',\n",
       "  b'roe_deer_s_000097.png',\n",
       "  b'car_s_001575.png',\n",
       "  b'flying_bird_s_000133.png',\n",
       "  b'arabian_s_000228.png',\n",
       "  b'chihuahua_s_002232.png',\n",
       "  b'pleasure_boat_s_000419.png',\n",
       "  b'pekingese_s_000828.png',\n",
       "  b'capreolus_capreolus_s_000190.png',\n",
       "  b'propeller_plane_s_001393.png',\n",
       "  b'biplane_s_000521.png',\n",
       "  b'felis_catus_s_000627.png',\n",
       "  b'mule_deer_s_000159.png',\n",
       "  b'lipizzan_s_001201.png',\n",
       "  b'car_s_000008.png',\n",
       "  b'domestic_cat_s_000788.png',\n",
       "  b'jetliner_s_001984.png',\n",
       "  b'aerial_ladder_truck_s_000495.png',\n",
       "  b'auto_s_002023.png',\n",
       "  b'walking_horse_s_001744.png',\n",
       "  b'aerial_ladder_truck_s_000030.png',\n",
       "  b'wagtail_s_000538.png',\n",
       "  b'propeller_plane_s_001131.png',\n",
       "  b'cervus_elaphus_s_000071.png',\n",
       "  b'mouser_s_000185.png',\n",
       "  b'lippizan_s_000913.png',\n",
       "  b'canis_familiaris_s_000274.png',\n",
       "  b'semi_s_001613.png',\n",
       "  b'meadow_pipit_s_000749.png',\n",
       "  b'house_cat_s_001330.png',\n",
       "  b'dawn_horse_s_001460.png',\n",
       "  b'tabby_s_001209.png',\n",
       "  b'maltese_dog_s_000463.png',\n",
       "  b'bufo_s_000365.png',\n",
       "  b'boat_s_000870.png',\n",
       "  b'cock_s_000599.png',\n",
       "  b'amphibious_aircraft_s_000377.png',\n",
       "  b'lapdog_s_001066.png',\n",
       "  b'maltese_s_000903.png',\n",
       "  b'airliner_s_000109.png',\n",
       "  b'leopard_frog_s_001554.png',\n",
       "  b'tabby_cat_s_002690.png',\n",
       "  b'sambar_s_000226.png',\n",
       "  b'tipper_s_000805.png',\n",
       "  b'dog_s_001749.png',\n",
       "  b'coupe_s_001480.png',\n",
       "  b'semi_s_000161.png',\n",
       "  b'pleasure_boat_s_001331.png',\n",
       "  b'rangifer_tarandus_s_001190.png',\n",
       "  b'fighter_s_000467.png',\n",
       "  b'tomcat_s_000509.png',\n",
       "  b'gelding_s_001762.png',\n",
       "  b'cavalry_horse_s_000913.png',\n",
       "  b'barge_s_000025.png',\n",
       "  b'wagon_s_002540.png',\n",
       "  b'rana_clamitans_s_000365.png',\n",
       "  b'trucking_rig_s_001294.png',\n",
       "  b'domestic_cat_s_001414.png',\n",
       "  b'convertible_s_000152.png',\n",
       "  b'odocoileus_hemionus_s_001021.png',\n",
       "  b'freighter_s_001580.png',\n",
       "  b'dawn_horse_s_001833.png',\n",
       "  b'american_elk_s_000517.png',\n",
       "  b'tennessee_walking_horse_s_001177.png',\n",
       "  b'peke_s_000227.png',\n",
       "  b'toy_dog_s_000071.png',\n",
       "  b'tank_ship_s_000451.png',\n",
       "  b'convertible_s_002579.png',\n",
       "  b'stealth_bomber_s_000303.png',\n",
       "  b'tennessee_walker_s_000891.png',\n",
       "  b'broodmare_s_000708.png',\n",
       "  b'fighter_aircraft_s_000537.png',\n",
       "  b'mongrel_s_000394.png',\n",
       "  b'bufo_bufo_s_000587.png',\n",
       "  b'american_toad_s_000178.png',\n",
       "  b'tennessee_walking_horse_s_001248.png',\n",
       "  b'jumbojet_s_000366.png',\n",
       "  b'toad_frog_s_001286.png',\n",
       "  b'domestic_dog_s_001386.png',\n",
       "  b'puppy_s_000022.png',\n",
       "  b'cat_s_002365.png',\n",
       "  b'house_cat_s_001766.png',\n",
       "  b'fire_truck_s_002590.png',\n",
       "  b'lippizaner_s_000806.png',\n",
       "  b'roe_deer_s_000533.png',\n",
       "  b'broodmare_s_000952.png',\n",
       "  b'bufo_marinus_s_000317.png',\n",
       "  b'auto_s_000209.png',\n",
       "  b'tabby_s_001809.png',\n",
       "  b'dog_s_000124.png',\n",
       "  b'honey_eater_s_000904.png',\n",
       "  b'convertible_s_002354.png',\n",
       "  b'wagon_s_000499.png',\n",
       "  b'fallow_deer_s_000674.png',\n",
       "  b'shooting_brake_s_001252.png',\n",
       "  b'guard_boat_s_000001.png',\n",
       "  b'cow_pony_s_000990.png',\n",
       "  b'biplane_s_002001.png',\n",
       "  b'tabby_s_000616.png',\n",
       "  b'estate_car_s_000820.png',\n",
       "  b'airliner_s_001409.png',\n",
       "  b'jumbojet_s_000270.png',\n",
       "  b'bufo_bufo_s_002091.png',\n",
       "  b'broodmare_s_000498.png',\n",
       "  b'delivery_truck_s_000098.png',\n",
       "  b'cassowary_s_000191.png',\n",
       "  b'lipizzan_s_001429.png',\n",
       "  b'arabian_s_001327.png',\n",
       "  b'boat_s_002668.png',\n",
       "  b'english_toy_spaniel_s_000007.png',\n",
       "  b'tabby_s_000661.png',\n",
       "  b'sparrow_s_000465.png',\n",
       "  b'stealth_bomber_s_000988.png',\n",
       "  b'camion_s_000510.png',\n",
       "  b'lark_s_001747.png',\n",
       "  b'odocoileus_hemionus_s_001027.png',\n",
       "  b'elk_s_000540.png',\n",
       "  b'cassowary_s_002387.png',\n",
       "  b'domestic_cat_s_001129.png',\n",
       "  b'western_toad_s_000920.png',\n",
       "  b'puppy_s_000083.png',\n",
       "  b'stud_mare_s_001230.png',\n",
       "  b'canis_familiaris_s_000777.png',\n",
       "  b'bufo_s_001484.png',\n",
       "  b'monoplane_s_001543.png',\n",
       "  b'lippizaner_s_001318.png',\n",
       "  b'pekingese_s_002482.png',\n",
       "  b'sambar_s_000011.png',\n",
       "  b'caribou_s_001206.png',\n",
       "  b'boat_s_000755.png',\n",
       "  b'twinjet_s_000523.png',\n",
       "  b'pipit_s_001067.png',\n",
       "  b'dama_dama_s_000175.png',\n",
       "  b'mailboat_s_000413.png',\n",
       "  b'mouser_s_000747.png',\n",
       "  b'struthio_camelus_s_000916.png',\n",
       "  b'banana_boat_s_002023.png',\n",
       "  b'estate_car_s_001140.png',\n",
       "  b'moose_s_000718.png',\n",
       "  b'passerine_s_001827.png',\n",
       "  b'stealth_fighter_s_000495.png',\n",
       "  b'cat_s_001703.png',\n",
       "  b'cat_s_002235.png',\n",
       "  b'powerboat_s_000752.png',\n",
       "  b'gelding_s_000593.png',\n",
       "  b'fire_truck_s_000769.png',\n",
       "  b'buckskin_s_000144.png',\n",
       "  b'bird_s_001241.png',\n",
       "  b'banana_boat_s_000376.png',\n",
       "  b'dumper_s_002083.png',\n",
       "  b'shooting_brake_s_001455.png',\n",
       "  b'ratite_s_000324.png',\n",
       "  b'japanese_deer_s_000879.png',\n",
       "  b'police_cruiser_s_000929.png',\n",
       "  b'bufo_viridis_s_000336.png',\n",
       "  b'dog_s_001395.png',\n",
       "  b'deer_s_001544.png',\n",
       "  b'tabby_cat_s_000481.png',\n",
       "  b'american_toad_s_000435.png',\n",
       "  b'leopard_frog_s_002121.png',\n",
       "  b'dive_bomber_s_001027.png',\n",
       "  b'powerboat_s_001551.png',\n",
       "  b'houseboat_s_000548.png',\n",
       "  b'alces_alces_s_000762.png',\n",
       "  b'cervus_sika_s_000063.png',\n",
       "  b'police_cruiser_s_000329.png',\n",
       "  b'broodmare_s_001543.png',\n",
       "  b'police_cruiser_s_000314.png',\n",
       "  b'packet_boat_s_001267.png',\n",
       "  b'lightship_s_001969.png',\n",
       "  b'bufo_viridis_s_000963.png',\n",
       "  b'auto_s_000282.png',\n",
       "  b'rana_catesbeiana_s_001086.png',\n",
       "  b'airliner_s_001779.png',\n",
       "  b'wagtail_s_001333.png',\n",
       "  b'convertible_s_002150.png',\n",
       "  b'tabby_s_002006.png',\n",
       "  b'woodland_caribou_s_001257.png',\n",
       "  b'station_wagon_s_000779.png',\n",
       "  b'airbus_s_000682.png',\n",
       "  b'toy_dog_s_001274.png',\n",
       "  b'truck_s_001383.png',\n",
       "  b'fire_truck_s_001200.png',\n",
       "  b'bird_s_001401.png',\n",
       "  b'red_deer_s_000109.png',\n",
       "  b'trucking_rig_s_001307.png',\n",
       "  b'lightship_s_000465.png',\n",
       "  b'speedboat_s_000507.png',\n",
       "  b'frog_s_002295.png',\n",
       "  b'broodmare_s_000019.png',\n",
       "  b'stealth_fighter_s_000488.png',\n",
       "  b'blenheim_spaniel_s_001006.png',\n",
       "  b'dog_s_000725.png',\n",
       "  b'maltese_s_001518.png',\n",
       "  b'wagtail_s_001643.png',\n",
       "  b'cavalry_horse_s_001786.png',\n",
       "  b'freighter_s_000222.png',\n",
       "  b'fighter_aircraft_s_000979.png',\n",
       "  b'attack_aircraft_s_000974.png',\n",
       "  b'bufo_boreas_s_000051.png',\n",
       "  b'icebreaker_s_000004.png',\n",
       "  b'car_s_000218.png',\n",
       "  b'auto_s_001146.png',\n",
       "  b'passenger_ship_s_000570.png',\n",
       "  b'monoplane_s_001071.png',\n",
       "  b'river_boat_s_000468.png',\n",
       "  b'wagtail_s_001485.png',\n",
       "  b'arabian_s_000327.png',\n",
       "  b'stud_mare_s_001310.png',\n",
       "  b'stealth_fighter_s_001668.png',\n",
       "  b'saddle_horse_s_001655.png',\n",
       "  b'container_ship_s_001505.png',\n",
       "  b'biplane_s_000135.png',\n",
       "  b'airbus_s_002205.png',\n",
       "  b'lapdog_s_001393.png',\n",
       "  b'mutt_s_000781.png',\n",
       "  b'compact_car_s_001131.png',\n",
       "  b'red_deer_s_000540.png',\n",
       "  b'lipizzan_s_000030.png',\n",
       "  b'maltese_s_000930.png',\n",
       "  b'rangifer_tarandus_s_000414.png',\n",
       "  b'garbage_truck_s_001200.png',\n",
       "  b'caribou_s_001155.png',\n",
       "  b'wagtail_s_001305.png',\n",
       "  b'roe_deer_s_000011.png',\n",
       "  b'hospital_ship_s_000044.png',\n",
       "  b'maltese_s_000931.png',\n",
       "  b'green_frog_s_000300.png',\n",
       "  b'tabby_cat_s_000516.png',\n",
       "  b'odocoileus_hemionus_s_001098.png',\n",
       "  b'cervus_sika_s_000079.png',\n",
       "  b'tank_ship_s_001651.png',\n",
       "  b'mutt_s_001083.png',\n",
       "  b'domestic_dog_s_001508.png',\n",
       "  b'compact_s_000688.png',\n",
       "  b'arabian_s_001759.png',\n",
       "  b'stealth_bomber_s_000671.png',\n",
       "  b'coupe_s_001568.png',\n",
       "  b'domestic_dog_s_001207.png',\n",
       "  b'twinjet_s_001329.png',\n",
       "  b'tow_car_s_000013.png',\n",
       "  b'spadefoot_s_000809.png',\n",
       "  b'capreolus_capreolus_s_001418.png',\n",
       "  b'rangifer_tarandus_s_000886.png',\n",
       "  b'liberty_ship_s_001091.png',\n",
       "  b'alley_cat_s_002779.png',\n",
       "  b'dump_truck_s_000879.png',\n",
       "  b'puppy_s_000540.png',\n",
       "  b'accentor_s_001244.png',\n",
       "  b'chihuahua_s_002116.png',\n",
       "  b'dawn_horse_s_001907.png',\n",
       "  b'fallow_deer_s_001948.png',\n",
       "  b'airliner_s_002059.png',\n",
       "  b'stallion_s_001074.png',\n",
       "  b'domestic_cat_s_001665.png',\n",
       "  b'dive_bomber_s_000686.png',\n",
       "  b'bufo_marinus_s_000068.png',\n",
       "  b'dawn_horse_s_000058.png',\n",
       "  b'stallion_s_001533.png',\n",
       "  b'deer_s_001898.png',\n",
       "  b'pekinese_s_000777.png',\n",
       "  b'spring_frog_s_001570.png',\n",
       "  b'puppy_s_000939.png',\n",
       "  b'pekinese_s_001489.png',\n",
       "  b'airliner_s_000567.png',\n",
       "  b'emu_s_000269.png',\n",
       "  b'aerial_ladder_truck_s_000358.png',\n",
       "  b'pekingese_s_000178.png',\n",
       "  b'tabby_s_001146.png',\n",
       "  b'mouser_s_000545.png',\n",
       "  b'car_s_000724.png',\n",
       "  b'beach_wagon_s_001033.png',\n",
       "  b'tabby_s_001972.png',\n",
       "  b'cassowary_s_001381.png',\n",
       "  b'tow_truck_s_000654.png',\n",
       "  b'domestic_cat_s_000298.png',\n",
       "  b'mouser_s_000690.png',\n",
       "  b'tennessee_walker_s_000722.png',\n",
       "  b'car_s_000453.png',\n",
       "  b'ostrich_s_002467.png',\n",
       "  b'toad_frog_s_000216.png',\n",
       "  b'peke_s_000648.png',\n",
       "  b'japanese_spaniel_s_000627.png',\n",
       "  b'pekinese_s_002310.png',\n",
       "  b'monoplane_s_000964.png',\n",
       "  b'camion_s_001791.png',\n",
       "  b'dredger_s_000413.png',\n",
       "  b'biplane_s_000379.png',\n",
       "  b'muntjac_s_001781.png',\n",
       "  b'fallow_deer_s_001281.png',\n",
       "  b'struthio_camelus_s_000391.png',\n",
       "  b'puppy_s_000261.png',\n",
       "  b'tractor_trailer_s_000478.png',\n",
       "  b'true_cat_s_000370.png',\n",
       "  b'beach_wagon_s_000868.png',\n",
       "  b'arabian_s_000547.png',\n",
       "  b'ship_s_000543.png',\n",
       "  b'bufo_americanus_s_001648.png',\n",
       "  b'dredger_s_000285.png',\n",
       "  b'fighter_aircraft_s_000001.png',\n",
       "  b'jumbojet_s_001660.png',\n",
       "  b'tennessee_walker_s_001044.png',\n",
       "  b'lippizaner_s_000435.png',\n",
       "  b'mongrel_s_001438.png',\n",
       "  b'dump_truck_s_000110.png',\n",
       "  b'monoplane_s_000769.png',\n",
       "  b'toad_s_000027.png',\n",
       "  b'domestic_cat_s_000452.png',\n",
       "  b'boat_s_000764.png',\n",
       "  b'texas_toad_s_000212.png',\n",
       "  b'airbus_s_001881.png',\n",
       "  b'cat_s_000034.png',\n",
       "  b'tennessee_walker_s_000743.png',\n",
       "  b'motorcar_s_001136.png',\n",
       "  b'delivery_truck_s_001376.png',\n",
       "  b'bufo_viridis_s_000822.png',\n",
       "  b'aerial_ladder_truck_s_000251.png',\n",
       "  b'texas_toad_s_000688.png',\n",
       "  b'automobile_s_000541.png',\n",
       "  b'reconnaissance_plane_s_000863.png',\n",
       "  b'coupe_s_000502.png',\n",
       "  b'stealth_bomber_s_000047.png',\n",
       "  b'lorry_s_002149.png',\n",
       "  b'puppy_s_001782.png',\n",
       "  b'apteryx_s_000128.png',\n",
       "  b'cassowary_s_001992.png',\n",
       "  b'maltese_s_002290.png',\n",
       "  b'fighter_aircraft_s_001485.png',\n",
       "  b'pilot_boat_s_001290.png',\n",
       "  b'dump_truck_s_001224.png',\n",
       "  b'ostrich_s_000684.png',\n",
       "  b'cervus_elaphus_s_001493.png',\n",
       "  b'cat_s_000755.png',\n",
       "  b'boat_s_002644.png',\n",
       "  b'jetliner_s_000253.png',\n",
       "  b'propeller_plane_s_002256.png',\n",
       "  b'tennessee_walker_s_000745.png',\n",
       "  b'tabby_cat_s_001201.png',\n",
       "  b'leopard_frog_s_001988.png',\n",
       "  b'arabian_s_001649.png',\n",
       "  b'tugboat_s_000713.png',\n",
       "  b'lipizzan_s_000015.png',\n",
       "  b'auto_s_000839.png',\n",
       "  b'king_charles_spaniel_s_000103.png',\n",
       "  b'rana_pipiens_s_000042.png',\n",
       "  b'ferry_s_000146.png',\n",
       "  b'quarter_horse_s_002167.png',\n",
       "  b'auto_s_002280.png',\n",
       "  b'tabby_cat_s_000418.png',\n",
       "  b'shooting_brake_s_001156.png',\n",
       "  b'tipper_truck_s_000766.png',\n",
       "  b'rana_temporaria_s_000562.png',\n",
       "  b'dump_truck_s_002163.png',\n",
       "  b'moving_van_s_002389.png',\n",
       "  b'puppy_s_001930.png',\n",
       "  b'automobile_s_000424.png',\n",
       "  b'meadow_pipit_s_001288.png',\n",
       "  b'fawn_s_000183.png',\n",
       "  b'pekinese_s_001847.png',\n",
       "  b'police_boat_s_002071.png',\n",
       "  b'frog_s_000005.png',\n",
       "  b'cervus_elaphus_s_000063.png',\n",
       "  b'taxi_s_001121.png',\n",
       "  b'motorboat_s_000143.png',\n",
       "  b'bufo_bufo_s_001869.png',\n",
       "  b'sparrow_s_002379.png',\n",
       "  b'mouser_s_001175.png',\n",
       "  b'pekinese_s_001615.png',\n",
       "  b'tipper_truck_s_001039.png',\n",
       "  b'automobile_s_001883.png',\n",
       "  b'airbus_s_001325.png',\n",
       "  b'motorboat_s_001646.png',\n",
       "  b'mule_deer_s_001567.png',\n",
       "  b'camion_s_000878.png',\n",
       "  b'alces_alces_s_001223.png',\n",
       "  b'arabian_s_001379.png',\n",
       "  b'lorry_s_000553.png',\n",
       "  b'tomcat_s_001123.png',\n",
       "  b'jumbo_jet_s_000105.png',\n",
       "  b'ferryboat_s_000084.png',\n",
       "  b'mouser_s_000993.png',\n",
       "  b'broodmare_s_001534.png',\n",
       "  b'tipper_truck_s_000125.png',\n",
       "  b'honey_eater_s_000785.png',\n",
       "  b'fawn_s_000982.png',\n",
       "  b'puppy_s_000657.png',\n",
       "  b'blenheim_spaniel_s_000322.png',\n",
       "  b'passenger_ship_s_000546.png',\n",
       "  b'fallow_deer_s_000436.png',\n",
       "  b'rhea_s_000034.png',\n",
       "  b'attack_aircraft_s_000791.png',\n",
       "  b'wagon_s_002607.png',\n",
       "  b'alley_cat_s_001083.png',\n",
       "  b'tabby_cat_s_001729.png',\n",
       "  b'appaloosa_s_002019.png',\n",
       "  b'fighter_aircraft_s_001646.png',\n",
       "  b'dawn_horse_s_000228.png',\n",
       "  b'stallion_s_000009.png',\n",
       "  b'fawn_s_001608.png',\n",
       "  b'cargo_vessel_s_001571.png',\n",
       "  b'odocoileus_hemionus_s_000545.png',\n",
       "  b'mongrel_s_002488.png',\n",
       "  b'broodmare_s_001113.png',\n",
       "  b'dog_s_000490.png',\n",
       "  b'dump_truck_s_000157.png',\n",
       "  b'wagon_s_001422.png',\n",
       "  b'house_cat_s_000650.png',\n",
       "  b'arabian_s_001329.png',\n",
       "  b'bird_s_001439.png',\n",
       "  b'dawn_horse_s_001174.png',\n",
       "  b'tennessee_walking_horse_s_001644.png',\n",
       "  b'sambar_s_000314.png',\n",
       "  b'rana_pipiens_s_000047.png',\n",
       "  b'muntjac_s_001155.png',\n",
       "  b'stallion_s_000477.png',\n",
       "  b'lippizan_s_001215.png',\n",
       "  b'stealth_fighter_s_000094.png',\n",
       "  b'trucking_rig_s_001667.png',\n",
       "  b'coupe_s_001143.png',\n",
       "  b'stealth_bomber_s_002149.png',\n",
       "  b'maltese_s_001424.png',\n",
       "  b'rhea_americana_s_000052.png',\n",
       "  b'fire_engine_s_001105.png',\n",
       "  b'red_deer_s_001255.png',\n",
       "  b'accentor_s_000028.png',\n",
       "  b'convertible_s_000267.png',\n",
       "  b'boat_s_002392.png',\n",
       "  b'barking_deer_s_000260.png',\n",
       "  b'broodmare_s_001518.png',\n",
       "  b'merchant_ship_s_000023.png',\n",
       "  b'chihuahua_s_002120.png',\n",
       "  b'crapaud_s_000259.png',\n",
       "  b'rana_pipiens_s_000982.png',\n",
       "  b'convertible_s_001285.png',\n",
       "  b'stealth_bomber_s_000622.png',\n",
       "  b'convertible_s_002821.png',\n",
       "  b'dama_dama_s_000100.png',\n",
       "  b'toy_spaniel_s_000146.png',\n",
       "  b'camion_s_001552.png',\n",
       "  b'stud_mare_s_000939.png',\n",
       "  b'showboat_s_000155.png',\n",
       "  b'house_cat_s_001098.png',\n",
       "  b'racing_boat_s_000769.png',\n",
       "  b'bufo_americanus_s_000037.png',\n",
       "  b'mongrel_s_001145.png',\n",
       "  b'bufo_boreas_s_000518.png',\n",
       "  b'police_boat_s_001423.png',\n",
       "  b'puppy_s_000985.png',\n",
       "  b'deer_s_000240.png',\n",
       "  b'bird_s_001118.png',\n",
       "  b'arabian_s_002391.png',\n",
       "  b'merchant_ship_s_000471.png',\n",
       "  b'cat_s_000440.png',\n",
       "  b'fire_truck_s_001826.png',\n",
       "  b'felis_catus_s_001161.png',\n",
       "  b'gelding_s_001120.png',\n",
       "  b'nandu_s_000453.png',\n",
       "  b'moving_van_s_002636.png',\n",
       "  b'alauda_arvensis_s_000727.png',\n",
       "  b'pickerel_frog_s_001042.png',\n",
       "  b'mouser_s_000214.png',\n",
       "  b'green_frog_s_001215.png',\n",
       "  b'bufo_americanus_s_000529.png',\n",
       "  b'prunella_modularis_s_000589.png',\n",
       "  b'dump_truck_s_001410.png',\n",
       "  b'domestic_cat_s_000017.png',\n",
       "  b'wrecker_s_002186.png',\n",
       "  b'alauda_arvensis_s_001182.png',\n",
       "  b'pekinese_s_000648.png',\n",
       "  b'rana_catesbeiana_s_000914.png',\n",
       "  b'mule_deer_s_001686.png',\n",
       "  b'tabby_s_001296.png',\n",
       "  b'tabby_cat_s_000014.png',\n",
       "  b'moose_s_000133.png',\n",
       "  b'elk_s_001800.png',\n",
       "  b'stealth_fighter_s_001606.png',\n",
       "  b'police_cruiser_s_001361.png',\n",
       "  b'stealth_bomber_s_001880.png',\n",
       "  b'attack_aircraft_s_001408.png',\n",
       "  b'passenger_ship_s_002143.png',\n",
       "  b'dawn_horse_s_001973.png',\n",
       "  b'house_cat_s_001099.png',\n",
       "  b'nandu_s_001704.png',\n",
       "  b'tabby_cat_s_001565.png',\n",
       "  b'toad_s_000997.png',\n",
       "  b'oil_tanker_s_001415.png',\n",
       "  b'estate_car_s_000141.png',\n",
       "  b'coupe_s_000455.png',\n",
       "  b'powerboat_s_000727.png',\n",
       "  b'japanese_deer_s_000869.png',\n",
       "  b'tabby_s_002096.png',\n",
       "  b'cassowary_s_001587.png',\n",
       "  b'police_cruiser_s_000090.png',\n",
       "  b'moose_s_000588.png',\n",
       "  b'chihuahua_s_002320.png',\n",
       "  b'lorry_s_000302.png',\n",
       "  b'elk_s_002048.png',\n",
       "  b'cargo_vessel_s_000013.png',\n",
       "  b'freighter_s_001151.png',\n",
       "  b'finch_s_000496.png',\n",
       "  b'car_s_001963.png',\n",
       "  b'mongrel_s_002561.png',\n",
       "  b'american_elk_s_000609.png',\n",
       "  b'cabin_cruiser_s_001680.png',\n",
       "  b'cat_s_000802.png',\n",
       "  b'american_elk_s_001386.png',\n",
       "  b'ladder_truck_s_000112.png',\n",
       "  b'natterjack_s_000688.png',\n",
       "  b'grass_frog_s_001403.png',\n",
       "  b'cabin_cruiser_s_000245.png',\n",
       "  b'amphibious_aircraft_s_001416.png',\n",
       "  b'gelding_s_001632.png',\n",
       "  b'jumbojet_s_001058.png',\n",
       "  b'plane_s_001282.png',\n",
       "  b'emu_s_000364.png',\n",
       "  b'taxi_s_001242.png',\n",
       "  b'cat_s_000445.png',\n",
       "  b'dawn_horse_s_000754.png',\n",
       "  b'maltese_dog_s_001140.png',\n",
       "  b'lorry_s_001937.png',\n",
       "  b'powerboat_s_000756.png',\n",
       "  b'riding_horse_s_000964.png',\n",
       "  b'tabby_cat_s_002125.png',\n",
       "  ...]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['loaded'][f'data\\\\data_batch_{random.randint(1, 5)}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5eef0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'airplane',\n",
       " b'automobile',\n",
       " b'bird',\n",
       " b'cat',\n",
       " b'deer',\n",
       " b'dog',\n",
       " b'frog',\n",
       " b'horse',\n",
       " b'ship',\n",
       " b'truck']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['meta'][b'label_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d97d109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = data['train']['loaded'][f'data\\\\data_batch_{random.randint(1, 5)}']\n",
    "targetIndex = random.randint(0, len(target[b'data']) - 1)\n",
    "label = target[b'labels'][targetIndex]\n",
    "label = f\"{data['meta'][b'label_names'][label].decode('UTF-8')} ({label})\"\n",
    "\n",
    "showImg(\n",
    "    target[b'data'][targetIndex].reshape(3, 32, 32).transpose(1, 2, 0),\n",
    "    f\"Label: {label}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96679807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[158, 159, 165, ..., 124, 129, 110],\n",
       "       [235, 231, 232, ..., 178, 191, 199],\n",
       "       [158, 158, 139, ...,   8,   3,   7],\n",
       "       ...,\n",
       "       [ 20,  19,  15, ...,  50,  53,  47],\n",
       "       [ 25,  15,  23, ...,  80,  81,  80],\n",
       "       [ 73,  98,  99, ...,  94,  58,  26]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['test']['loaded'][b'data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8298fd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target = data['test']['loaded']\n",
    "targetIndex = random.randint(0, len(target[b'data']) - 1)\n",
    "label = target[b'labels'][targetIndex]\n",
    "label = f\"{data['meta'][b'label_names'][label].decode('UTF-8')} ({label})\"\n",
    "\n",
    "showImg(\n",
    "    data['test']['loaded'][b'data'][targetIndex].reshape(3, 32, 32).transpose(1, 2, 0),\n",
    "    f\"Label: {label}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c193a02",
   "metadata": {},
   "source": [
    "## Process\n",
    "\n",
    "Here begins the process which includes data splitting and pre-processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034cebad",
   "metadata": {},
   "source": [
    "### Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f364ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not applicable for this dataset... It'll be handled in the Pre-Processing step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e843657c",
   "metadata": {},
   "source": [
    "### Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8995b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train']['processed'] = {\n",
    "    'combined': {\n",
    "        'data': None,\n",
    "        'labels': None,\n",
    "        'generators': {\n",
    "\t\t\t224: None,\n",
    "\t\t\t299: None\n",
    "\t\t}\n",
    "    },\n",
    "    'validation': {\n",
    "        'data': None,\n",
    "        'labels': None,\n",
    "        'generators': {\n",
    "\t\t\t224: None,\n",
    "\t\t\t299: None\n",
    "\t\t}\n",
    "    },\n",
    "}\n",
    "\n",
    "data['test']['processed'] = {\n",
    "    'generators': {\n",
    "\t\t224: None,\n",
    "\t\t299: None\n",
    "\t}\n",
    "}\n",
    "\n",
    "# Splitting the data into training and validation sets\n",
    "x = []\n",
    "y = []\n",
    "for file in data['train']['loaded']:\n",
    "    x.append(data['train']['loaded'][file][b'data'])\n",
    "    y.append(data['train']['loaded'][file][b'labels'])\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    np.concatenate(x),\n",
    "    np.concatenate(y),\n",
    "    test_size = 0.2\n",
    ")\n",
    "\n",
    "# Reshaping the data to match the input shape of the model - THIS IS SO STUPID\n",
    "for targetShape in [224, 299]:\n",
    "\ttargetSize = (targetShape, targetShape)\n",
    "    \n",
    "\t#######################\n",
    "\t### VALIDATION DATA ###\n",
    "\t#######################\n",
    "\tdata['train']['processed']['validation']['data'] = x_val\n",
    "\tdata['train']['processed']['validation']['labels'] = y_val\n",
    "\tdata['train']['processed']['validation']['generators'][targetShape] = makeDataset(\n",
    "\t\tdata['train']['processed']['validation']['data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1),\n",
    "\t\tdata['train']['processed']['validation']['labels'],\n",
    "\t\ttargetSize\n",
    "\t)\n",
    " \n",
    "\t# data['train']['processed']['validation']['generators'][targetShape] = (ImageDataGenerator(\n",
    "\t# \trescale = 1./255,\n",
    "\t# )).flow(\n",
    "    #  \tresize(\n",
    "\t# \t\tdata['train']['processed']['validation']['data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1),\n",
    "\t# \t\ttargetSize\n",
    "\t# \t).numpy(),\n",
    "\t# \tdata['train']['processed']['validation']['labels'],\n",
    "\t# )\n",
    "\n",
    "\t##################\n",
    "\t### TRAIN DATA ###\n",
    "\t##################\n",
    "\tdata['train']['processed']['combined']['data'] = x_train\n",
    "\tdata['train']['processed']['combined']['labels'] = y_train\n",
    "\tdata['train']['processed']['combined']['generators'][targetShape] = makeDataset(\n",
    "\t\tdata['train']['processed']['combined']['data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1),\n",
    "\t\tdata['train']['processed']['combined']['labels'],\n",
    "\t\ttargetSize,\n",
    "\t\tTrue\n",
    "\t)\n",
    "\n",
    "\t# data['train']['processed']['combined']['generators'][targetShape] = (ImageDataGenerator(\n",
    "\t# \trescale = 1./255,\n",
    "\t# \trotation_range = 20,\n",
    "\t# \twidth_shift_range = 0.2,\n",
    "\t# \theight_shift_range = 0.2,\n",
    "\t# \tshear_range = 0.2,\n",
    "\t# \tzoom_range = 0.2,\n",
    "\t# \thorizontal_flip = True\n",
    "\t# )).flow(\n",
    "\t# \tresize(\n",
    "\t# \t\tdata['train']['processed']['combined']['data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1),\n",
    "\t# \t\ttargetSize\n",
    "\t# \t).numpy(),\n",
    "\t# \tdata['train']['processed']['combined']['labels'],\n",
    "\t# )\n",
    "\n",
    "\t### -------------\n",
    "\t###\n",
    "\t### -------------\n",
    "\n",
    "\t#################\n",
    "\t### TEST DATA ###\n",
    "\t#################\n",
    "\tdata['test']['processed']['generators'][targetShape] = makeDataset(\n",
    "\t\tdata['test']['loaded'][b'data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1),\n",
    "\t\tdata['test']['loaded'][b'labels'],\n",
    "\t\ttargetSize\n",
    "\t)\n",
    "\n",
    "\t# data['test']['processed']['generators'][targetShape] = (ImageDataGenerator(\n",
    "\t# \trescale = 1./255,\n",
    "\t# )).flow(\n",
    "\t# \tresize(\n",
    "\t# \t\tdata['test']['loaded'][b'data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1),\n",
    "\t# \t\ttargetSize\n",
    "\t# \t).numpy(),\n",
    "\t# \tdata['test']['loaded'][b'labels'],\n",
    "\t# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e07eef4",
   "metadata": {},
   "source": [
    "### Creating the Model\n",
    "\n",
    "Includes the compilation and fitting after using 10 configuration samples to learn how they affect the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "066858d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'baseModel': <function keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
       "  'trainBase': True,\n",
       "  'poolingLayer': keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D,\n",
       "  'dropoutRate': 0.4,\n",
       "  'denseUnits': 512,\n",
       "  'useBatchNorm': False,\n",
       "  'hlDecayMode': 'l1',\n",
       "  'hlDecayRate': 0.0001,\n",
       "  'opDecayMode': 'l1_l2',\n",
       "  'opDecayRate': 0.001},\n",
       " {'baseModel': <function keras.applications.inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')>,\n",
       "  'trainBase': True,\n",
       "  'poolingLayer': keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D,\n",
       "  'dropoutRate': 0.3,\n",
       "  'denseUnits': 896,\n",
       "  'useBatchNorm': True,\n",
       "  'hlDecayMode': 'l2',\n",
       "  'hlDecayRate': 0.0001,\n",
       "  'opDecayMode': 'l1_l2',\n",
       "  'opDecayRate': 0.001}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs = randomConfigSampler(configCombinations, 2)\n",
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c313afb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------------------\n",
      "-- CONFIGURATION --\n",
      "-------------------\n",
      "\n",
      "\n",
      "Base Model: VGG16\n",
      "Pooling Layer: Flatten\n",
      "Train Base: True\n",
      "Dropout Rate: 0.4\n",
      "Dense Units: 512\n",
      "Use Batch Norm: False\n",
      "Hidden Layer Decay Mode: l1\n",
      "Hidden Layer Decay Rate: 0.0001\n",
      "Output Layer Decay Mode: l1_l2\n",
      "Output Layer Decay Rate: 0.001\n",
      "\n",
      "\n",
      "--------------------\n",
      "-- BUILDING MODEL --\n",
      "--------------------\n",
      "\n",
      "\n",
      "Resizing Layer Shape:  (None, 224, 224, 3)\n",
      "VGG16 Input: KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n",
      "VGG16 Output: KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 512), dtype=tf.float32, name=None), name='block5_pool/MaxPool:0', description=\"created by layer 'block5_pool'\")\n",
      "Pooling Layer Shape: (None, 25088)\n",
      "Hidden Layer Shape: (None, 512)\n",
      "Dropout Layer Shape: (None, 512)\n",
      "Output Layer Shape: (None, 10)\n"
     ]
    }
   ],
   "source": [
    "configs[0]['baseModel'] = VGG16\n",
    "configs[0]['poolingLayer'] = Flatten\n",
    "\n",
    "cnf = configs[0]\n",
    "\n",
    "print('\\n\\n-------------------')\n",
    "print('-- CONFIGURATION --')\n",
    "print('-------------------\\n\\n')\n",
    "\n",
    "print(f'Base Model: {cnf[\"baseModel\"].__name__}')\n",
    "print(f'Pooling Layer: {cnf[\"poolingLayer\"].__name__}')\n",
    "print(f'Train Base: {cnf[\"trainBase\"]}')\n",
    "print(f'Dropout Rate: {cnf[\"dropoutRate\"]}')\n",
    "print(f'Dense Units: {cnf[\"denseUnits\"]}')\n",
    "print(f'Use Batch Norm: {cnf[\"useBatchNorm\"]}')\n",
    "print(f'Hidden Layer Decay Mode: {cnf[\"hlDecayMode\"]}')\n",
    "print(f'Hidden Layer Decay Rate: {cnf[\"hlDecayRate\"]}')\n",
    "print(f'Output Layer Decay Mode: {cnf[\"opDecayMode\"]}')\n",
    "print(f'Output Layer Decay Rate: {cnf[\"opDecayRate\"]}')\n",
    "\n",
    "print('\\n\\n--------------------')\n",
    "print('-- BUILDING MODEL --')\n",
    "print('--------------------\\n\\n')\n",
    "\n",
    "# Applies the resizing layer to the input shape\n",
    "targetShape = (299, 299) if cnf['baseModel'] is InceptionV3 else (224, 224)\n",
    "inputTensor = Input(shape = (32, 32, 3))\n",
    "inputTensor = Resizing(*targetShape)(inputTensor)\n",
    "print(\"Resizing Layer Shape: \", inputTensor.shape)\n",
    "    \n",
    "baseModel = cnf['baseModel'](\n",
    "    weights = 'imagenet',\n",
    "    include_top = False,\n",
    "    input_tensor = Input(shape = (299, 299, 3) if cnf['baseModel'] is InceptionV3 else (224, 224, 3))\n",
    ")\n",
    "baseModel.trainable = cnf['trainBase']\n",
    "print(f\"{cnf['baseModel'].__name__} Input: {baseModel.input}\")\n",
    "print(f\"{cnf['baseModel'].__name__} Output: {baseModel.output}\")\n",
    "\n",
    "x = cnf['poolingLayer']()(baseModel.output)\n",
    "print(f\"Pooling Layer Shape: {x.shape}\")\n",
    "\n",
    "if cnf['useBatchNorm']:\n",
    "\tx = BatchNormalization()(x)\n",
    "\tprint(f\"Batch Normalization Shape: {x.shape}\")\n",
    "\n",
    "hlKernelRegularizer = None\n",
    "if cnf['hlDecayMode'] in ('l1', 'l2', 'l1_l2') and cnf['hlDecayRate'] > 0:\n",
    "\tif cnf['hlDecayMode'] == 'l1':\n",
    "\t\thlKernelRegularizer = l1(cnf['hlDecayRate'])\n",
    "\telif cnf['hlDecayMode'] == 'l2':\n",
    "\t\thlKernelRegularizer = l2(cnf['hlDecayRate'])\n",
    "\telif cnf['hlDecayMode'] == 'l1_l2':\n",
    "\t\tif cnf['hlDecayRate'] is list:\n",
    "\t\t\thlKernelRegularizer = l1_l2(cnf['hlDecayRate'][0], cnf['hlDecayRate'][1])\n",
    "\t\telse:\n",
    "\t\t\thlKernelRegularizer = l1_l2(cnf['hlDecayRate'], cnf['hlDecayRate'])\n",
    "x = Dense(cnf['denseUnits'], activation = \"relu\", kernel_regularizer = hlKernelRegularizer)(x)\n",
    "print(f\"Hidden Layer Shape: {x.shape}\")\n",
    "\n",
    "if cnf['useBatchNorm']:\n",
    "\tx = BatchNormalization()(x)\n",
    "\tprint(f\"Batch Normalization Shape: {x.shape}\")\n",
    "\n",
    "if cnf['dropoutRate'] > 0:\n",
    "\tx = Dropout(cnf['dropoutRate'])(x)\n",
    "\tprint(f\"Dropout Layer Shape: {x.shape}\")\n",
    "\n",
    "opKernelRegularizer = None\n",
    "if cnf['opDecayMode'] in ('l1', 'l2', 'l1_l2') and cnf['opDecayRate'] > 0:\n",
    "\tif cnf['opDecayMode'] == 'l1':\n",
    "\t\topKernelRegularizer = l1(cnf['opDecayRate'])\n",
    "\telif cnf['opDecayMode'] == 'l2':\n",
    "\t\topKernelRegularizer = l2(cnf['opDecayRate'])\n",
    "\telif cnf['opDecayMode'] == 'l1_l2':\n",
    "\t\tif cnf['opDecayRate'] is list:\n",
    "\t\t\topKernelRegularizer = l1_l2(cnf['opDecayRate'][0], cnf['opDecayRate'][1])\n",
    "\t\telse:\n",
    "\t\t\topKernelRegularizer = l1_l2(cnf['opDecayRate'], cnf['opDecayRate'])\n",
    "x = Dense(10, activation = \"relu\", kernel_regularizer = opKernelRegularizer)(x)\n",
    "print(f\"Output Layer Shape: {x.shape}\")\n",
    "\n",
    "model = Model(inputs = baseModel.input, outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093d4666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds a custom \"good\" config\n",
    "goodConfigs = [\n",
    "    {\n",
    "        'baseModel': ResNet50,\n",
    "\t\t'trainBase': False,\n",
    "\t\t'poolingLayer': GlobalAveragePooling2D,\n",
    "\t\t'dropoutRate': 0.5,\n",
    "\t\t'denseUnits': 512,\n",
    "\t\t'useBatchNorm': True,\n",
    "\t\t'hlDecayMode': 'l2',\n",
    "\t\t'hlDecayRate': 0.001,\n",
    "\t\t'opDecayMode': 'l2',\n",
    "\t\t'opDecayRate': 0.001\n",
    "\t},\n",
    "    {\n",
    "\t\t'baseModel': InceptionV3,\n",
    "\t\t'trainBase': False,\n",
    "\t\t'poolingLayer': GlobalAveragePooling2D,\n",
    "\t\t'dropoutRate': 0.5,\n",
    "\t\t'denseUnits': 512,\n",
    "\t\t'useBatchNorm': True,\n",
    "\t\t'hlDecayMode': 'l2',\n",
    "\t\t'hlDecayRate': 0.001,\n",
    "\t\t'opDecayMode': 'l2',\n",
    "\t\t'opDecayRate': 0.001\n",
    "\t},\n",
    "    {\n",
    "\t\t'baseModel': VGG16,\n",
    "\t\t'trainBase': False,\n",
    "\t\t'poolingLayer': GlobalAveragePooling2D,\n",
    "\t\t'dropoutRate': 0.5,\n",
    "\t\t'denseUnits': 512,\n",
    "\t\t'useBatchNorm': True,\n",
    "\t\t'hlDecayMode': 'l2',\n",
    "\t\t'hlDecayRate': 0.001,\n",
    "\t\t'opDecayMode': 'l2',\n",
    "\t\t'opDecayRate': 0.001\n",
    "\t}\n",
    "]\n",
    "\n",
    "for conf in goodConfigs:\n",
    "\tconfigs.insert(0, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b486668",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 15\n",
    "\n",
    "# Steps per Epoch\n",
    "SPE = 250\n",
    "print(f\"Potential SPE (224): {len(data['train']['processed']['combined']['data']) // batchSize}\")\n",
    "print(f\"Potential SPE (299): {len(data['train']['processed']['combined']['data']) // batchSize}\")\n",
    "# Validation Steps\n",
    "VS = 100\n",
    "print(f\"Potential VS (224): {len(data['train']['processed']['validation']['data']) // batchSize}\")\n",
    "print(f\"Potential VS (299): {len(data['train']['processed']['validation']['data']) // batchSize}\")\n",
    "print(\"\")\n",
    "\n",
    "for i, config in enumerate(configs):\n",
    "\talias = models[\"aliases\"][config['baseModel'].__name__]\n",
    "\tprint(f\"\\n\\nConfig {i + 1}/{len(configs)} ({alias}):\")\n",
    "\tprint(f\"Config: {config}\")\n",
    "\n",
    "\tmodel = buildModel(**config)\n",
    "\n",
    "\t# Save the configuration for later reference/use. Also, the model too.\n",
    "\tmodels['configs'][alias].append(config)\n",
    "\tmodels['fitted'][alias].append(model)\n",
    "\n",
    "\t# Compile the model\n",
    "\tmodel.compile(\n",
    "\t\toptimizer = Adam(learning_rate = 1e-4),\n",
    "\t\tloss = 'sparse_categorical_crossentropy',\n",
    "\t\tmetrics = ['accuracy'],\n",
    "\t)\n",
    "\n",
    "\t# Fit the model\n",
    "\ttargetShape = 299 if config['baseModel'] is InceptionV3 else 224\n",
    "\tstartTime = time.time()\n",
    "\thistory = model.fit(\n",
    "\t\tdata['train']['processed']['combined']['generators'][targetShape].repeat(),\n",
    "\t\tsteps_per_epoch = SPE,\n",
    "\t\tepochs = 100,\n",
    "\t\tvalidation_data = data['train']['processed']['validation']['generators'][targetShape].repeat(),\n",
    "\t\tvalidation_steps = VS,\n",
    "\t\tverbose = 2,\n",
    "\t\tcallbacks = callbacks,\n",
    "\t\tuse_multiprocessing = True,\n",
    "\t)\n",
    "\tendTime = time.time()\n",
    "\tmodelProfiler.append(endTime - startTime)\n",
    "\tprint(f\"Model {alias} took {endTime - startTime:.2f} seconds to train.\\n\\n\")\n",
    "\n",
    "\t# Prediction\n",
    "\tgenerator = copy(data['test']['processed']['generators'][targetShape])\n",
    "\n",
    "\tmetrics, yTrue, yPred = getMetrics(\n",
    "\t\tmodel,\n",
    "\t\tgenerator,\n",
    "\t\tlogPerBatch = False\n",
    "\t)\n",
    "\tavg, min, max = metrics\n",
    "\n",
    "\t# Show model training history\n",
    "\tplotModelHistory(\n",
    "\t\talias,\n",
    "\t\thistory,\n",
    "\t\tavg,\n",
    "\t\tyTrue,\n",
    "\t\tyPred\n",
    "\t)\n",
    "\n",
    "\t# Show confusion matrix\n",
    "\tplotConfusionMatrix(\n",
    "\t\tyTrue,\n",
    "\t\tyPred,\n",
    "\t\talias,\n",
    "\t\tavg\n",
    "\t)\n",
    "\n",
    "\t# Show model architecture\n",
    "\tplotModel(\n",
    "\t\tmodel,\n",
    "\t\tavg,\n",
    "\t\talias\n",
    "\t)\n",
    "\n",
    "\t# Freeing up memory\n",
    "\tK.clear_session()\n",
    "\tdel model\n",
    "\tgc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
